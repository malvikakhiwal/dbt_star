

============================== 2022-11-23 05:49:26.027830 | 037101dd-0f62-4a27-a73b-0db60365d26c ==============================
[0m05:49:26.027836 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:49:26.028049 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/.dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m05:49:26.028117 [debug] [MainThread]: Tracking: tracking
[0m05:49:26.043987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10334dd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10334d8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10331de20>]}
[0m05:49:26.056954 [debug] [MainThread]: Executing "git --help"
[0m05:49:26.079868 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m05:49:26.080295 [debug] [MainThread]: STDERR: "b''"
[0m05:49:26.080571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100451be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1033cf1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1033cf100>]}
[0m05:49:26.080797 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 05:49:50.364187 | ee55acff-31d0-4c1b-bdc2-3ffd13c86acf ==============================
[0m05:49:50.364193 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:49:50.364394 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m05:49:50.364464 [debug] [MainThread]: Tracking: tracking
[0m05:49:50.381095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a88f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a659d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a55ac0>]}
[0m05:49:50.702238 [debug] [MainThread]: Executing "git --help"
[0m05:49:50.725795 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m05:49:50.726160 [debug] [MainThread]: STDERR: "b''"
[0m05:49:50.732740 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m05:49:50.733405 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:49:56.745648 [debug] [MainThread]: BigQuery adapter: Got an error when attempting to create a bigquery client: 'Runtime Error
  
  dbt encountered an error while trying to read your profiles.yml file.
  
  Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started
  '
[0m05:49:56.746317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073308e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073305e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10730c5b0>]}
[0m05:49:56.746646 [debug] [MainThread]: Flushing usage events
[0m05:49:56.954912 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 05:50:38.221687 | 899845c7-4d6a-4441-9140-0f86b51ce44a ==============================
[0m05:50:38.221693 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:50:38.221891 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m05:50:38.221964 [debug] [MainThread]: Tracking: tracking
[0m05:50:38.238145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105210f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051ede20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105210b50>]}
[0m05:50:38.558498 [debug] [MainThread]: Executing "git --help"
[0m05:50:38.580935 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m05:50:38.581290 [debug] [MainThread]: STDERR: "b''"
[0m05:50:38.585270 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m05:50:38.586211 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:50:44.594559 [debug] [MainThread]: BigQuery adapter: Got an error when attempting to create a bigquery client: 'Runtime Error
  
  dbt encountered an error while trying to read your profiles.yml file.
  
  Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started
  '
[0m05:50:44.595066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ab0bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ab0850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a7b2b0>]}
[0m05:50:44.595355 [debug] [MainThread]: Flushing usage events
[0m05:50:44.829909 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 06:02:52.399286 | 4dec0fb7-2343-4fb8-bc3d-ac2d2f5df461 ==============================
[0m06:02:52.399293 [info ] [MainThread]: Running with dbt=1.3.0
[0m06:02:52.399655 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m06:02:52.399724 [debug] [MainThread]: Tracking: tracking
[0m06:02:52.417432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712cf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107109e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712cb50>]}
[0m06:02:52.786663 [debug] [MainThread]: Executing "git --help"
[0m06:02:52.810205 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m06:02:52.810587 [debug] [MainThread]: STDERR: "b''"
[0m06:02:52.814360 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m06:02:52.815099 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:02:53.238987 [debug] [MainThread]: On debug: select 1 as id
[0m06:02:54.499134 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:dc627b7e-9799-4a8e-be03-f03301362aa1:northamerica-northeast1&page=queryresults
[0m06:02:54.500756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10867c580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10867c2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10867c490>]}
[0m06:02:54.501548 [debug] [MainThread]: Flushing usage events
[0m06:02:54.741092 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 06:06:04.823228 | ff811ee7-9df7-4570-b032-0782a830afda ==============================
[0m06:06:04.823233 [info ] [MainThread]: Running with dbt=1.3.0
[0m06:06:04.823408 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m06:06:04.823471 [debug] [MainThread]: Tracking: tracking
[0m06:06:04.843945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107934f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107911e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107934550>]}
[0m06:06:05.179621 [debug] [MainThread]: Executing "git --help"
[0m06:06:05.204750 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m06:06:05.205085 [debug] [MainThread]: STDERR: "b''"
[0m06:06:05.208327 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m06:06:05.209028 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:06:05.639858 [debug] [MainThread]: On debug: select 1 as id
[0m06:06:06.723435 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:b8311516-5fde-4f5b-b5fd-2855ea9e712b:northamerica-northeast1&page=queryresults
[0m06:06:06.724001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a184760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a1847c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a1846d0>]}
[0m06:06:06.724269 [debug] [MainThread]: Flushing usage events
[0m06:06:06.983414 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 06:09:26.779660 | 58f55463-1c57-41dd-884a-3e806144a50c ==============================
[0m06:09:26.779689 [info ] [MainThread]: Running with dbt=1.3.0
[0m06:09:26.780043 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m06:09:26.780125 [debug] [MainThread]: Tracking: tracking
[0m06:09:26.800549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cd3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cd39d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cd3970>]}
[0m06:09:26.808878 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
[0m06:09:26.809058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e03ac0>]}
[0m06:09:26.839422 [debug] [MainThread]: Parsing macros/etc.sql
[0m06:09:26.840761 [debug] [MainThread]: Parsing macros/catalog.sql
[0m06:09:26.844512 [debug] [MainThread]: Parsing macros/adapters.sql
[0m06:09:26.855517 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m06:09:26.856704 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m06:09:26.858055 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m06:09:26.861924 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m06:09:26.863220 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m06:09:26.872067 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m06:09:26.872835 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m06:09:26.873003 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m06:09:26.873294 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m06:09:26.873784 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m06:09:26.873945 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m06:09:26.874205 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m06:09:26.874503 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m06:09:26.874988 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m06:09:26.875561 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m06:09:26.875786 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m06:09:26.876013 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m06:09:26.876256 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m06:09:26.876486 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m06:09:26.876680 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m06:09:26.877430 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m06:09:26.877678 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m06:09:26.878070 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m06:09:26.878346 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m06:09:26.879568 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m06:09:26.881388 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m06:09:26.882452 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m06:09:26.883242 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m06:09:26.891438 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m06:09:26.898891 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m06:09:26.905659 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m06:09:26.907907 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m06:09:26.908758 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m06:09:26.909674 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m06:09:26.913747 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m06:09:26.922521 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m06:09:26.923252 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m06:09:26.926748 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m06:09:26.932024 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m06:09:26.941722 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m06:09:26.944510 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m06:09:26.946205 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m06:09:26.948938 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m06:09:26.949591 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m06:09:26.951271 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m06:09:26.952406 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m06:09:26.956116 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m06:09:26.966490 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m06:09:26.967253 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m06:09:26.968430 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m06:09:26.969162 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m06:09:26.969575 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m06:09:26.969947 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m06:09:26.970271 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m06:09:26.970929 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m06:09:26.973525 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m06:09:26.977844 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m06:09:26.978232 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m06:09:26.978835 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m06:09:26.979281 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m06:09:26.979711 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m06:09:26.980292 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m06:09:26.980662 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m06:09:26.981156 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m06:09:26.981759 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m06:09:26.982951 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m06:09:26.983592 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m06:09:26.984115 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m06:09:26.984618 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m06:09:26.985099 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m06:09:26.985520 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m06:09:26.986017 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m06:09:26.986431 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m06:09:26.989705 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m06:09:26.990194 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m06:09:26.990615 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m06:09:26.991479 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m06:09:26.992562 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m06:09:26.993044 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m06:09:26.993736 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m06:09:26.994214 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m06:09:26.995223 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m06:09:26.996807 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m06:09:26.998151 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m06:09:27.005789 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m06:09:27.006743 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m06:09:27.013445 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m06:09:27.015582 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m06:09:27.019162 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m06:09:27.024257 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m06:09:27.027333 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m06:09:27.161660 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m06:09:27.167920 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m06:09:27.234817 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m06:09:27.237897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e98040>]}
[0m06:09:27.242920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e031c0>]}
[0m06:09:27.243156 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m06:09:27.243283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e44bb0>]}
[0m06:09:27.243981 [info ] [MainThread]: 
[0m06:09:27.244346 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m06:09:27.244860 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m06:09:27.244985 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:28.528472 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m06:09:28.528918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:28.804338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b47e80>]}
[0m06:09:28.805995 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:09:28.806415 [info ] [MainThread]: 
[0m06:09:28.815875 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m06:09:28.816301 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m06:09:28.817036 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m06:09:28.817197 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m06:09:28.817390 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m06:09:28.822188 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m06:09:28.823843 [debug] [Thread-1  ]: finished collecting timing info
[0m06:09:28.824044 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m06:09:28.859141 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m06:09:28.860394 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m06:09:28.860527 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m06:09:30.829356 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:765ce238-ac71-4c59-ae02-4ef0235c7329:northamerica-northeast1&page=queryresults
[0m06:09:30.843399 [debug] [Thread-1  ]: finished collecting timing info
[0m06:09:30.843917 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ea8d60>]}
[0m06:09:30.844181 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.03s]
[0m06:09:30.844464 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m06:09:30.844851 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m06:09:30.845035 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m06:09:30.845485 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m06:09:30.845585 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m06:09:30.845671 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m06:09:30.847833 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m06:09:30.848406 [debug] [Thread-3  ]: finished collecting timing info
[0m06:09:30.848516 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m06:09:30.863635 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m06:09:30.864426 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m06:09:30.864617 [debug] [Thread-3  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m06:09:31.596782 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:b19b9157-8145-4565-bddc-cdb45ea95558:northamerica-northeast1&page=queryresults
[0m06:09:31.598469 [debug] [Thread-3  ]: finished collecting timing info
[0m06:09:31.599109 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58f55463-1c57-41dd-884a-3e806144a50c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112081a30>]}
[0m06:09:31.599524 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.75s]
[0m06:09:31.599941 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m06:09:31.601367 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m06:09:31.601869 [info ] [MainThread]: 
[0m06:09:31.602086 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.36 seconds (4.36s).
[0m06:09:31.602278 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:09:31.602381 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m06:09:31.602464 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m06:09:31.611882 [info ] [MainThread]: 
[0m06:09:31.612159 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:09:31.612348 [info ] [MainThread]: 
[0m06:09:31.612486 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:09:31.612857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e44880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e69970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120865e0>]}
[0m06:09:31.613035 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 07:03:04.692484 | ed7b035f-7b75-467b-9b6f-0f35ae148296 ==============================
[0m07:03:04.692491 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:03:04.692690 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m07:03:04.692753 [debug] [MainThread]: Tracking: tracking
[0m07:03:04.714053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a10d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039dabe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a09310>]}
[0m07:03:04.714660 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m07:03:04.715066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a10ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a092b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100b1e760>]}
[0m07:03:04.715196 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 07:04:13.157033 | 66b771ac-6e4a-470b-9de4-be56345ba7d3 ==============================
[0m07:04:13.157067 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:04:13.157412 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'resource_types': [], 'which': 'build', 'rpc_method': 'build'}
[0m07:04:13.157494 [debug] [MainThread]: Tracking: tracking
[0m07:04:13.174889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108695400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108695580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108695520>]}
[0m07:04:13.221770 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:04:13.221912 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:04:13.222108 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m07:04:13.225661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66b771ac-6e4a-470b-9de4-be56345ba7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10884dd60>]}
[0m07:04:13.230736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66b771ac-6e4a-470b-9de4-be56345ba7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108777e50>]}
[0m07:04:13.231035 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m07:04:13.231204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66b771ac-6e4a-470b-9de4-be56345ba7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108777e20>]}
[0m07:04:13.231915 [info ] [MainThread]: 
[0m07:04:13.232263 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:04:13.232734 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m07:04:13.232901 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:04:14.481791 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m07:04:14.482437 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:04:14.788420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66b771ac-6e4a-470b-9de4-be56345ba7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108686550>]}
[0m07:04:14.789125 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:04:14.789368 [info ] [MainThread]: 
[0m07:04:14.794181 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m07:04:14.794428 [info ] [Thread-1  ]: 1 of 6 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m07:04:14.794918 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m07:04:14.795040 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m07:04:14.795169 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m07:04:14.798235 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m07:04:14.798896 [debug] [Thread-1  ]: finished collecting timing info
[0m07:04:14.799064 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m07:04:14.811323 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:04:15.168352 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m07:04:15.169359 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m07:04:17.026865 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:8046fe64-11d5-49a9-b1c7-1dbe69b4d83b:northamerica-northeast1&page=queryresults
[0m07:04:17.049826 [debug] [Thread-1  ]: finished collecting timing info
[0m07:04:17.050386 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '66b771ac-6e4a-470b-9de4-be56345ba7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088ca130>]}
[0m07:04:17.050676 [info ] [Thread-1  ]: 1 of 6 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.26s]
[0m07:04:17.050997 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m07:04:17.051506 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:04:17.051714 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:04:17.051825 [info ] [Thread-3  ]: 2 of 6 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m07:04:17.051984 [info ] [Thread-4  ]: 3 of 6 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m07:04:17.052523 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:04:17.052986 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:04:17.053106 [debug] [Thread-3  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:04:17.053207 [debug] [Thread-4  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:04:17.053332 [debug] [Thread-3  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:04:17.053443 [debug] [Thread-4  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:04:17.064548 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:04:17.069477 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:04:17.071395 [debug] [Thread-4  ]: finished collecting timing info
[0m07:04:17.071539 [debug] [Thread-4  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:04:17.077668 [debug] [Thread-3  ]: finished collecting timing info
[0m07:04:17.081669 [debug] [Thread-4  ]: Writing runtime sql for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:04:17.081832 [debug] [Thread-3  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:04:17.083353 [debug] [Thread-3  ]: Writing runtime sql for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:04:17.083817 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m07:04:17.083932 [debug] [Thread-3  ]: On test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m07:04:17.084360 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m07:04:17.084457 [debug] [Thread-4  ]: On test.dbt_star.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m07:04:18.174690 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:a5a6b702-ed57-4412-820a-c6a29443a7e6:northamerica-northeast1&page=queryresults
[0m07:04:18.178296 [debug] [Thread-3  ]: finished collecting timing info
[0m07:04:18.179359 [error] [Thread-3  ]: 2 of 6 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 1.13s]
[0m07:04:18.180010 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:04:18.197453 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:1e78dfaf-4d23-48fb-a211-fb7927814cac:northamerica-northeast1&page=queryresults
[0m07:04:18.197963 [debug] [Thread-4  ]: finished collecting timing info
[0m07:04:18.198524 [info ] [Thread-4  ]: 3 of 6 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 1.15s]
[0m07:04:18.198890 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:04:18.199389 [debug] [Thread-1  ]: Began running node model.dbt_star.my_second_dbt_model
[0m07:04:18.199673 [info ] [Thread-1  ]: 4 of 6 SKIP relation dbt_sandbox16.my_second_dbt_model ......................... [[33mSKIP[0m]
[0m07:04:18.200076 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m07:04:18.200446 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:04:18.200625 [info ] [Thread-3  ]: 5 of 6 SKIP test not_null_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m07:04:18.200805 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:04:18.201079 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:04:18.201210 [info ] [Thread-4  ]: 6 of 6 SKIP test unique_my_second_dbt_model_id ................................. [[33mSKIP[0m]
[0m07:04:18.201649 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:04:18.202602 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:04:18.203054 [info ] [MainThread]: 
[0m07:04:18.203272 [info ] [MainThread]: Finished running 1 table model, 4 tests, 1 view model in 0 hours 0 minutes and 4.97 seconds (4.97s).
[0m07:04:18.203458 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:04:18.203546 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m07:04:18.203631 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m07:04:18.203713 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m07:04:18.213887 [info ] [MainThread]: 
[0m07:04:18.214155 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m07:04:18.214336 [info ] [MainThread]: 
[0m07:04:18.214485 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m07:04:18.214660 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m07:04:18.214794 [info ] [MainThread]: 
[0m07:04:18.214929 [info ] [MainThread]:   compiled Code at target/compiled/dbt_star/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m07:04:18.215082 [info ] [MainThread]: 
[0m07:04:18.215217 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=3 TOTAL=6
[0m07:04:18.215442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c1f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c1b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c1d90>]}
[0m07:04:18.215607 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 07:22:43.076456 | 0b84fd2f-fee2-4848-abb2-f38732423a16 ==============================
[0m07:22:43.076496 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:22:43.076880 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m07:22:43.076995 [debug] [MainThread]: Tracking: tracking
[0m07:22:43.094613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11235f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11235fa60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11235fa00>]}
[0m07:22:43.143992 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:22:43.144132 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:22:43.144349 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m07:22:43.147598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0b84fd2f-fee2-4848-abb2-f38732423a16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124f10d0>]}
[0m07:22:43.151958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0b84fd2f-fee2-4848-abb2-f38732423a16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11241e370>]}
[0m07:22:43.152103 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m07:22:43.152245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0b84fd2f-fee2-4848-abb2-f38732423a16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112345460>]}
[0m07:22:43.152949 [info ] [MainThread]: 
[0m07:22:43.153248 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:22:43.153675 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m07:22:43.153746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:22:45.082863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0b84fd2f-fee2-4848-abb2-f38732423a16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11235fa60>]}
[0m07:22:45.084399 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:22:45.084852 [info ] [MainThread]: 
[0m07:22:45.091112 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m07:22:45.091797 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m07:22:45.091994 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m07:22:45.092205 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m07:22:45.096170 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m07:22:45.096770 [debug] [Thread-1  ]: finished collecting timing info
[0m07:22:45.096937 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m07:22:45.097083 [debug] [Thread-1  ]: finished collecting timing info
[0m07:22:45.097640 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m07:22:45.098213 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m07:22:45.098421 [debug] [Thread-4  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:22:45.098849 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m07:22:45.098988 [debug] [Thread-2  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:22:45.099461 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:22:45.099607 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m07:22:45.100044 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:22:45.100189 [debug] [Thread-4  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:22:45.100313 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m07:22:45.100429 [debug] [Thread-2  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:22:45.100538 [debug] [Thread-4  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:22:45.102967 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m07:22:45.103104 [debug] [Thread-2  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:22:45.114375 [debug] [Thread-2  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:22:45.122670 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:22:45.122854 [debug] [Thread-3  ]: finished collecting timing info
[0m07:22:45.122997 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m07:22:45.123096 [debug] [Thread-2  ]: finished collecting timing info
[0m07:22:45.123202 [debug] [Thread-3  ]: finished collecting timing info
[0m07:22:45.123341 [debug] [Thread-2  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:22:45.123768 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m07:22:45.123870 [debug] [Thread-4  ]: finished collecting timing info
[0m07:22:45.123953 [debug] [Thread-2  ]: finished collecting timing info
[0m07:22:45.124175 [debug] [Thread-4  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:22:45.124263 [debug] [Thread-1  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:22:45.124362 [debug] [Thread-3  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:22:45.124671 [debug] [Thread-2  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:22:45.124773 [debug] [Thread-4  ]: finished collecting timing info
[0m07:22:45.125056 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m07:22:45.125328 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m07:22:45.125689 [debug] [Thread-4  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:22:45.125786 [debug] [Thread-1  ]: Began compiling node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:22:45.125868 [debug] [Thread-3  ]: Began compiling node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:22:45.125999 [debug] [Thread-1  ]: Compiling test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:22:45.126081 [debug] [Thread-3  ]: Compiling test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:22:45.128847 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m07:22:45.131550 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m07:22:45.131952 [debug] [Thread-1  ]: finished collecting timing info
[0m07:22:45.132051 [debug] [Thread-3  ]: finished collecting timing info
[0m07:22:45.132136 [debug] [Thread-1  ]: Began executing node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:22:45.132227 [debug] [Thread-3  ]: Began executing node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:22:45.132316 [debug] [Thread-1  ]: finished collecting timing info
[0m07:22:45.132411 [debug] [Thread-3  ]: finished collecting timing info
[0m07:22:45.132735 [debug] [Thread-1  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:22:45.133057 [debug] [Thread-3  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:22:45.133569 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:22:45.133658 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m07:22:45.133729 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m07:22:45.133797 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m07:22:45.133859 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m07:22:45.138189 [info ] [MainThread]: Done.
[0m07:22:45.140323 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m07:22:45.140406 [info ] [MainThread]: Building catalog
[0m07:22:45.140671 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:22:45.557365 [debug] [ThreadPool]: Acquiring new bigquery connection "ae-recruitment-sandbox.information_schema"
[0m07:22:45.577670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:22:45.577931 [debug] [ThreadPool]: On ae-recruitment-sandbox.information_schema: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "connection_name": "ae-recruitment-sandbox.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.__TABLES__
        where (upper(dataset_id) = upper('dbt_sandbox16'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m07:22:47.627882 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:5c0e812d-c138-42fe-8986-d66262e2cc3e:northamerica-northeast1&page=queryresults
[0m07:22:47.650339 [info ] [MainThread]: Catalog written to /Users/jitesh.soni/Documents/Code/dbt_star/target/catalog.json
[0m07:22:47.650704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11235f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112551df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112551670>]}
[0m07:22:47.650899 [debug] [MainThread]: Flushing usage events
[0m07:22:47.883635 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m07:22:47.884031 [debug] [MainThread]: Connection 'ae-recruitment-sandbox.information_schema' was properly closed.


============================== 2022-11-23 07:30:46.397239 | 120534c1-24d4-41b5-992d-08bc2aa729b2 ==============================
[0m07:30:46.397267 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:30:46.397590 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m07:30:46.397687 [debug] [MainThread]: Tracking: tracking
[0m07:30:46.416638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095e71c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095e7340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095e72e0>]}
[0m07:30:46.461339 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:30:46.461475 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:30:46.461669 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m07:30:46.464921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '120534c1-24d4-41b5-992d-08bc2aa729b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097700d0>]}
[0m07:30:46.469136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '120534c1-24d4-41b5-992d-08bc2aa729b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969fd00>]}
[0m07:30:46.469291 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m07:30:46.469406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '120534c1-24d4-41b5-992d-08bc2aa729b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10969fd90>]}
[0m07:30:46.470060 [info ] [MainThread]: 
[0m07:30:46.470363 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:30:46.470788 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m07:30:46.470885 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:30:47.522105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '120534c1-24d4-41b5-992d-08bc2aa729b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109734f70>]}
[0m07:30:47.523578 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:30:47.523941 [info ] [MainThread]: 
[0m07:30:47.529547 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m07:30:47.530201 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m07:30:47.530371 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m07:30:47.530557 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m07:30:47.534911 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m07:30:47.535819 [debug] [Thread-1  ]: finished collecting timing info
[0m07:30:47.535985 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m07:30:47.536142 [debug] [Thread-1  ]: finished collecting timing info
[0m07:30:47.536764 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m07:30:47.537455 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m07:30:47.537950 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m07:30:47.538100 [debug] [Thread-4  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:30:47.538192 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m07:30:47.538285 [debug] [Thread-2  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:30:47.538693 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:30:47.538812 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m07:30:47.539175 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:30:47.539286 [debug] [Thread-4  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:30:47.541926 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m07:30:47.542098 [debug] [Thread-2  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:30:47.542215 [debug] [Thread-4  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:30:47.542381 [debug] [Thread-2  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:30:47.553317 [debug] [Thread-2  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m07:30:47.559087 [debug] [Thread-3  ]: finished collecting timing info
[0m07:30:47.561675 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m07:30:47.561815 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m07:30:47.561961 [debug] [Thread-3  ]: finished collecting timing info
[0m07:30:47.562036 [debug] [Thread-2  ]: finished collecting timing info
[0m07:30:47.562431 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m07:30:47.562545 [debug] [Thread-2  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:30:47.562643 [debug] [Thread-4  ]: finished collecting timing info
[0m07:30:47.562795 [debug] [Thread-2  ]: finished collecting timing info
[0m07:30:47.562943 [debug] [Thread-4  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:30:47.563021 [debug] [Thread-1  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:30:47.563113 [debug] [Thread-3  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:30:47.563414 [debug] [Thread-2  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m07:30:47.563501 [debug] [Thread-4  ]: finished collecting timing info
[0m07:30:47.563772 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m07:30:47.564049 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m07:30:47.564418 [debug] [Thread-4  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m07:30:47.564502 [debug] [Thread-1  ]: Began compiling node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:30:47.564581 [debug] [Thread-3  ]: Began compiling node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:30:47.564706 [debug] [Thread-1  ]: Compiling test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:30:47.564778 [debug] [Thread-3  ]: Compiling test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:30:47.567599 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m07:30:47.570325 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m07:30:47.570792 [debug] [Thread-1  ]: finished collecting timing info
[0m07:30:47.570878 [debug] [Thread-3  ]: finished collecting timing info
[0m07:30:47.570957 [debug] [Thread-1  ]: Began executing node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:30:47.571035 [debug] [Thread-3  ]: Began executing node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:30:47.571113 [debug] [Thread-1  ]: finished collecting timing info
[0m07:30:47.571188 [debug] [Thread-3  ]: finished collecting timing info
[0m07:30:47.571486 [debug] [Thread-1  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m07:30:47.571773 [debug] [Thread-3  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m07:30:47.572250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:30:47.572324 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m07:30:47.572386 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m07:30:47.572442 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m07:30:47.572496 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m07:30:47.576957 [info ] [MainThread]: Done.
[0m07:30:47.578252 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m07:30:47.578327 [info ] [MainThread]: Building catalog
[0m07:30:47.578609 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:30:48.077489 [debug] [ThreadPool]: Acquiring new bigquery connection "ae-recruitment-sandbox.information_schema"
[0m07:30:48.088450 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:30:48.088662 [debug] [ThreadPool]: On ae-recruitment-sandbox.information_schema: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "connection_name": "ae-recruitment-sandbox.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.__TABLES__
        where (upper(dataset_id) = upper('dbt_sandbox16'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m07:30:49.970572 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:5ddbf903-ef68-44b2-a484-729fd69daa1f:northamerica-northeast1&page=queryresults
[0m07:30:50.005016 [info ] [MainThread]: Catalog written to /Users/jitesh.soni/Documents/Code/dbt_star/target/catalog.json
[0m07:30:50.005598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109880a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109880e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098807c0>]}
[0m07:30:50.005920 [debug] [MainThread]: Flushing usage events
[0m07:30:50.252465 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m07:30:50.252994 [debug] [MainThread]: Connection 'ae-recruitment-sandbox.information_schema' was properly closed.


============================== 2022-11-23 16:39:49.759647 | 6a2adf8c-6217-495d-87f8-e6364f87523b ==============================
[0m16:39:49.759676 [info ] [MainThread]: Running with dbt=1.3.0
[0m16:39:49.760006 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m16:39:49.760109 [debug] [MainThread]: Tracking: tracking
[0m16:39:49.780217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bb31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bb3340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bb32e0>]}
[0m16:39:49.826273 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:39:49.826430 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:39:49.826634 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m16:39:49.829821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a2adf8c-6217-495d-87f8-e6364f87523b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d500d0>]}
[0m16:39:49.834182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a2adf8c-6217-495d-87f8-e6364f87523b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c84c10>]}
[0m16:39:49.834352 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:39:49.834483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a2adf8c-6217-495d-87f8-e6364f87523b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10612b370>]}
[0m16:39:49.835145 [info ] [MainThread]: 
[0m16:39:49.835453 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:39:49.835876 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m16:39:49.835988 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:51.332092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a2adf8c-6217-495d-87f8-e6364f87523b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d14f70>]}
[0m16:39:51.333609 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:39:51.334062 [info ] [MainThread]: 
[0m16:39:51.343301 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m16:39:51.343954 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m16:39:51.344131 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m16:39:51.344334 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m16:39:51.348911 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m16:39:51.350044 [debug] [Thread-1  ]: finished collecting timing info
[0m16:39:51.350208 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m16:39:51.350355 [debug] [Thread-1  ]: finished collecting timing info
[0m16:39:51.350901 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m16:39:51.351479 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m16:39:51.351683 [debug] [Thread-4  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:39:51.351822 [debug] [Thread-2  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:39:51.352242 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m16:39:51.352681 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:39:51.353047 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:39:51.353174 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m16:39:51.353301 [debug] [Thread-4  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:39:51.353420 [debug] [Thread-2  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:39:51.353535 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m16:39:51.353646 [debug] [Thread-4  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:39:51.353756 [debug] [Thread-2  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:39:51.356265 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m16:39:51.367030 [debug] [Thread-2  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:39:51.374858 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:39:51.375086 [debug] [Thread-3  ]: finished collecting timing info
[0m16:39:51.375195 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m16:39:51.375290 [debug] [Thread-3  ]: finished collecting timing info
[0m16:39:51.375648 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m16:39:51.375912 [debug] [Thread-4  ]: finished collecting timing info
[0m16:39:51.376013 [debug] [Thread-2  ]: finished collecting timing info
[0m16:39:51.376107 [debug] [Thread-1  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:39:51.376183 [debug] [Thread-4  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:39:51.376255 [debug] [Thread-3  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:39:51.376339 [debug] [Thread-2  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:39:51.376614 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m16:39:51.376704 [debug] [Thread-4  ]: finished collecting timing info
[0m16:39:51.376971 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:39:51.377056 [debug] [Thread-2  ]: finished collecting timing info
[0m16:39:51.377134 [debug] [Thread-1  ]: Began compiling node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:39:51.377444 [debug] [Thread-4  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:39:51.377526 [debug] [Thread-3  ]: Began compiling node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:39:51.377821 [debug] [Thread-2  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:39:51.377905 [debug] [Thread-1  ]: Compiling test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:39:51.378030 [debug] [Thread-3  ]: Compiling test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:39:51.380860 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m16:39:51.383421 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:39:51.383911 [debug] [Thread-1  ]: finished collecting timing info
[0m16:39:51.383998 [debug] [Thread-3  ]: finished collecting timing info
[0m16:39:51.384074 [debug] [Thread-1  ]: Began executing node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:39:51.384159 [debug] [Thread-3  ]: Began executing node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:39:51.384240 [debug] [Thread-1  ]: finished collecting timing info
[0m16:39:51.384319 [debug] [Thread-3  ]: finished collecting timing info
[0m16:39:51.384618 [debug] [Thread-1  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:39:51.384911 [debug] [Thread-3  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:39:51.385372 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:39:51.385449 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m16:39:51.385515 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m16:39:51.385578 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m16:39:51.385639 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m16:39:51.389946 [info ] [MainThread]: Done.
[0m16:39:51.391222 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m16:39:51.391307 [info ] [MainThread]: Building catalog
[0m16:39:51.391578 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:39:51.932051 [debug] [ThreadPool]: Acquiring new bigquery connection "ae-recruitment-sandbox.information_schema"
[0m16:39:51.951830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:51.952189 [debug] [ThreadPool]: On ae-recruitment-sandbox.information_schema: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "connection_name": "ae-recruitment-sandbox.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.__TABLES__
        where (upper(dataset_id) = upper('dbt_sandbox16'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m16:39:55.084083 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:95493adb-45c7-4e6b-9417-c7d9c5c00e26:northamerica-northeast1&page=queryresults
[0m16:39:55.102645 [info ] [MainThread]: Catalog written to /Users/jitesh.soni/Documents/Code/dbt_star/target/catalog.json
[0m16:39:55.103032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c84b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e60ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e60760>]}
[0m16:39:55.103251 [debug] [MainThread]: Flushing usage events
[0m16:39:55.498305 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:39:55.498889 [debug] [MainThread]: Connection 'ae-recruitment-sandbox.information_schema' was properly closed.


============================== 2022-11-23 16:41:15.316712 | e44adbbe-e68c-484c-8887-a02889bae8c9 ==============================
[0m16:41:15.316724 [info ] [MainThread]: Running with dbt=1.3.0
[0m16:41:15.317141 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m16:41:15.317235 [debug] [MainThread]: Tracking: tracking
[0m16:41:15.333558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f75b0>]}
[0m16:41:15.377164 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:41:15.377316 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:41:15.377504 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m16:41:15.380656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e44adbbe-e68c-484c-8887-a02889bae8c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10779afa0>]}
[0m16:41:15.384771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e44adbbe-e68c-484c-8887-a02889bae8c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107764040>]}
[0m16:41:15.384926 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:41:15.385054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e44adbbe-e68c-484c-8887-a02889bae8c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107758ee0>]}
[0m16:41:15.385717 [info ] [MainThread]: 
[0m16:41:15.386013 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:41:15.386444 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m16:41:15.386553 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:41:16.312711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e44adbbe-e68c-484c-8887-a02889bae8c9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c3820>]}
[0m16:41:16.314012 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:41:16.314353 [info ] [MainThread]: 
[0m16:41:16.319349 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m16:41:16.319922 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m16:41:16.320071 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m16:41:16.320244 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m16:41:16.324353 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m16:41:16.325257 [debug] [Thread-1  ]: finished collecting timing info
[0m16:41:16.325406 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m16:41:16.325542 [debug] [Thread-1  ]: finished collecting timing info
[0m16:41:16.326074 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m16:41:16.326609 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m16:41:16.327012 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m16:41:16.327134 [debug] [Thread-4  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:41:16.327236 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m16:41:16.327337 [debug] [Thread-2  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:41:16.327743 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:41:16.327862 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m16:41:16.328223 [debug] [Thread-2  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:41:16.328353 [debug] [Thread-4  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:41:16.330584 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m16:41:16.330713 [debug] [Thread-2  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:41:16.330812 [debug] [Thread-4  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:41:16.330963 [debug] [Thread-2  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:41:16.339649 [debug] [Thread-2  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:41:16.348351 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:41:16.348491 [debug] [Thread-3  ]: finished collecting timing info
[0m16:41:16.348633 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m16:41:16.348730 [debug] [Thread-2  ]: finished collecting timing info
[0m16:41:16.348832 [debug] [Thread-3  ]: finished collecting timing info
[0m16:41:16.348936 [debug] [Thread-2  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:41:16.349032 [debug] [Thread-4  ]: finished collecting timing info
[0m16:41:16.349368 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m16:41:16.349470 [debug] [Thread-2  ]: finished collecting timing info
[0m16:41:16.349567 [debug] [Thread-4  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:41:16.349776 [debug] [Thread-1  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:41:16.350095 [debug] [Thread-2  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:41:16.350176 [debug] [Thread-3  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:41:16.350266 [debug] [Thread-4  ]: finished collecting timing info
[0m16:41:16.350528 [debug] [Thread-1  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m16:41:16.350849 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:41:16.351148 [debug] [Thread-4  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:41:16.351235 [debug] [Thread-1  ]: Began compiling node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:41:16.351317 [debug] [Thread-3  ]: Began compiling node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:41:16.351452 [debug] [Thread-1  ]: Compiling test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:41:16.351533 [debug] [Thread-3  ]: Compiling test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:41:16.354173 [debug] [Thread-1  ]: Writing injected SQL for node "test.dbt_star.not_null_my_second_dbt_model_id.151b76d778"
[0m16:41:16.356600 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493"
[0m16:41:16.356937 [debug] [Thread-1  ]: finished collecting timing info
[0m16:41:16.357022 [debug] [Thread-3  ]: finished collecting timing info
[0m16:41:16.357091 [debug] [Thread-1  ]: Began executing node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:41:16.357175 [debug] [Thread-3  ]: Began executing node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:41:16.357253 [debug] [Thread-1  ]: finished collecting timing info
[0m16:41:16.357330 [debug] [Thread-3  ]: finished collecting timing info
[0m16:41:16.357617 [debug] [Thread-1  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:41:16.357903 [debug] [Thread-3  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:41:16.358341 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:41:16.358415 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
[0m16:41:16.358478 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m16:41:16.358539 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m16:41:16.358600 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m16:41:16.362884 [info ] [MainThread]: Done.
[0m16:41:16.364247 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m16:41:16.364321 [info ] [MainThread]: Building catalog
[0m16:41:16.364569 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:41:16.815135 [debug] [ThreadPool]: Acquiring new bigquery connection "ae-recruitment-sandbox.information_schema"
[0m16:41:16.835310 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:41:16.835635 [debug] [ThreadPool]: On ae-recruitment-sandbox.information_schema: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "connection_name": "ae-recruitment-sandbox.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.__TABLES__
        where (upper(dataset_id) = upper('dbt_sandbox16'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `ae-recruitment-sandbox`.`dbt_sandbox16`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m16:41:18.598598 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:5ac6d006-9969-46a3-9e86-1ab71010e7a5:northamerica-northeast1&page=queryresults
[0m16:41:18.619045 [info ] [MainThread]: Catalog written to /Users/jitesh.soni/Documents/Code/dbt_star/target/catalog.json
[0m16:41:18.619470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078a4610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078a4550>]}
[0m16:41:18.619700 [debug] [MainThread]: Flushing usage events
[0m16:41:18.879395 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:41:18.879708 [debug] [MainThread]: Connection 'ae-recruitment-sandbox.information_schema' was properly closed.


============================== 2022-11-23 16:45:53.569330 | 23ccef5e-2b40-4e95-875e-12e4bb9ac801 ==============================
[0m16:45:53.569339 [info ] [MainThread]: Running with dbt=1.3.0
[0m16:45:53.569537 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m16:45:53.569598 [debug] [MainThread]: Tracking: tracking
[0m16:45:53.585805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056c7700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056cc5b0>]}
[0m16:45:53.586539 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m16:45:53.586789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056cc1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056cc5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056cca90>]}
[0m16:45:53.586896 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 16:45:58.544349 | bcad9589-8139-43a1-bb89-df385a2e2b70 ==============================
[0m16:45:58.544356 [info ] [MainThread]: Running with dbt=1.3.0
[0m16:45:58.544557 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m16:45:58.544619 [debug] [MainThread]: Tracking: tracking
[0m16:45:58.561994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eebf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eca9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eb9ac0>]}
[0m16:45:58.888525 [debug] [MainThread]: Executing "git --help"
[0m16:45:58.912624 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:45:58.912976 [debug] [MainThread]: STDERR: "b''"
[0m16:45:58.916125 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m16:45:58.916867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:45:59.397541 [debug] [MainThread]: On debug: select 1 as id
[0m16:46:00.445384 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:33276035-3a03-4a1c-86ff-a8044f2f5a41:northamerica-northeast1&page=queryresults
[0m16:46:00.447382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10942a340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10942a430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10942a640>]}
[0m16:46:00.448721 [debug] [MainThread]: Flushing usage events
[0m16:46:00.680549 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 16:46:08.127405 | ad42ddd0-e626-45ab-bf60-7d91eeab5292 ==============================
[0m16:46:08.127445 [info ] [MainThread]: Running with dbt=1.3.0
[0m16:46:08.127851 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'resource_types': [], 'which': 'build', 'rpc_method': 'build'}
[0m16:46:08.127952 [debug] [MainThread]: Tracking: tracking
[0m16:46:08.144982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9e520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9e6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9e640>]}
[0m16:46:08.191943 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:46:08.192102 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:46:08.192316 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m16:46:08.196030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad42ddd0-e626-45ab-bf60-7d91eeab5292', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107155e80>]}
[0m16:46:08.200823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad42ddd0-e626-45ab-bf60-7d91eeab5292', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107119c40>]}
[0m16:46:08.201046 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:46:08.201167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad42ddd0-e626-45ab-bf60-7d91eeab5292', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eddfd0>]}
[0m16:46:08.201936 [info ] [MainThread]: 
[0m16:46:08.202304 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:46:08.202863 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m16:46:08.203008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:09.419422 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m16:46:09.419794 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:46:09.656625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad42ddd0-e626-45ab-bf60-7d91eeab5292', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9e730>]}
[0m16:46:09.657971 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:46:09.658339 [info ] [MainThread]: 
[0m16:46:09.664272 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m16:46:09.664704 [info ] [Thread-1  ]: 1 of 6 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m16:46:09.665414 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m16:46:09.665574 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m16:46:09.665769 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m16:46:09.669562 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m16:46:09.671202 [debug] [Thread-1  ]: finished collecting timing info
[0m16:46:09.671388 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m16:46:09.685815 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:46:09.938614 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m16:46:09.939382 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m16:46:11.790080 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:3e37c831-1d92-440e-8c02-ff369a544794:northamerica-northeast1&page=queryresults
[0m16:46:11.819060 [debug] [Thread-1  ]: finished collecting timing info
[0m16:46:11.819783 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad42ddd0-e626-45ab-bf60-7d91eeab5292', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107224b20>]}
[0m16:46:11.820194 [info ] [Thread-1  ]: 1 of 6 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.15s]
[0m16:46:11.820608 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m16:46:11.821281 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:46:11.821531 [info ] [Thread-3  ]: 2 of 6 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m16:46:11.822113 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:46:11.822256 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:46:11.822352 [debug] [Thread-3  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:46:11.822482 [info ] [Thread-4  ]: 3 of 6 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m16:46:11.822612 [debug] [Thread-3  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:46:11.823220 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:46:11.835042 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:46:11.835204 [debug] [Thread-4  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:46:11.835415 [debug] [Thread-4  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:46:11.840345 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:46:11.840639 [debug] [Thread-3  ]: finished collecting timing info
[0m16:46:11.840768 [debug] [Thread-3  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:46:11.847567 [debug] [Thread-4  ]: finished collecting timing info
[0m16:46:11.850284 [debug] [Thread-3  ]: Writing runtime sql for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m16:46:11.850372 [debug] [Thread-4  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:46:11.851747 [debug] [Thread-4  ]: Writing runtime sql for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m16:46:11.852284 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m16:46:11.852405 [debug] [Thread-4  ]: On test.dbt_star.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m16:46:11.853155 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:46:11.853252 [debug] [Thread-3  ]: On test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m16:46:12.792496 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:7a213ed8-f5f0-4d4f-a580-6378cda394c6:northamerica-northeast1&page=queryresults
[0m16:46:12.797235 [debug] [Thread-3  ]: finished collecting timing info
[0m16:46:12.799437 [error] [Thread-3  ]: 2 of 6 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.98s]
[0m16:46:12.800717 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m16:46:12.851435 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:6a70944e-34dd-48a4-97cf-0e35695e2ac8:northamerica-northeast1&page=queryresults
[0m16:46:12.852180 [debug] [Thread-4  ]: finished collecting timing info
[0m16:46:12.852825 [info ] [Thread-4  ]: 3 of 6 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 1.03s]
[0m16:46:12.853233 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m16:46:12.853716 [debug] [Thread-1  ]: Began running node model.dbt_star.my_second_dbt_model
[0m16:46:12.854022 [info ] [Thread-1  ]: 4 of 6 SKIP relation dbt_sandbox16.my_second_dbt_model ......................... [[33mSKIP[0m]
[0m16:46:12.854475 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m16:46:12.854876 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:46:12.855032 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:46:12.855188 [info ] [Thread-3  ]: 5 of 6 SKIP test not_null_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m16:46:12.855350 [info ] [Thread-4  ]: 6 of 6 SKIP test unique_my_second_dbt_model_id ................................. [[33mSKIP[0m]
[0m16:46:12.855670 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m16:46:12.855945 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m16:46:12.857377 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:46:12.857922 [info ] [MainThread]: 
[0m16:46:12.858136 [info ] [MainThread]: Finished running 1 table model, 4 tests, 1 view model in 0 hours 0 minutes and 4.66 seconds (4.66s).
[0m16:46:12.858323 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:46:12.858414 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m16:46:12.858499 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m16:46:12.858582 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m16:46:12.867518 [info ] [MainThread]: 
[0m16:46:12.867770 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:46:12.867948 [info ] [MainThread]: 
[0m16:46:12.868103 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m16:46:12.868259 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m16:46:12.868397 [info ] [MainThread]: 
[0m16:46:12.868533 [info ] [MainThread]:   compiled Code at target/compiled/dbt_star/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m16:46:12.868685 [info ] [MainThread]: 
[0m16:46:12.868819 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=3 TOTAL=6
[0m16:46:12.869040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072cbd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072cb430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072cbca0>]}
[0m16:46:12.869208 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 16:47:26.598624 | fc7c6d47-5536-496a-8d2d-9b359232d835 ==============================
[0m16:47:26.598640 [info ] [MainThread]: Running with dbt=1.3.0
[0m16:47:26.599048 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m16:47:26.599127 [debug] [MainThread]: Tracking: tracking
[0m16:47:26.621531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d46a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d4820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d47c0>]}
[0m16:47:26.667837 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:47:26.667977 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:47:26.668163 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m16:47:26.671667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fc7c6d47-5536-496a-8d2d-9b359232d835', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105779f40>]}
[0m16:47:26.676406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fc7c6d47-5536-496a-8d2d-9b359232d835', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105741040>]}
[0m16:47:26.676591 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m16:47:26.676719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc7c6d47-5536-496a-8d2d-9b359232d835', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105741070>]}
[0m16:47:26.677460 [info ] [MainThread]: 
[0m16:47:26.677816 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:47:26.678343 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m16:47:26.678486 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:47:27.818088 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m16:47:27.818298 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:47:28.054665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc7c6d47-5536-496a-8d2d-9b359232d835', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1041533d0>]}
[0m16:47:28.057436 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:47:28.058445 [info ] [MainThread]: 
[0m16:47:28.064139 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m16:47:28.064575 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m16:47:28.065332 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m16:47:28.065499 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m16:47:28.065717 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m16:47:28.069895 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m16:47:28.070803 [debug] [Thread-1  ]: finished collecting timing info
[0m16:47:28.071004 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m16:47:28.085108 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m16:47:28.377392 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m16:47:28.377964 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m16:47:30.278321 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:a9159576-8e18-4bb3-942e-a1db4007603e:northamerica-northeast1&page=queryresults
[0m16:47:30.300957 [debug] [Thread-1  ]: finished collecting timing info
[0m16:47:30.301681 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc7c6d47-5536-496a-8d2d-9b359232d835', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105764a00>]}
[0m16:47:30.302091 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.24s]
[0m16:47:30.302492 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m16:47:30.303286 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m16:47:30.303792 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m16:47:30.304429 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m16:47:30.304569 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m16:47:30.304694 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m16:47:30.307724 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m16:47:30.309836 [debug] [Thread-3  ]: finished collecting timing info
[0m16:47:30.309978 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m16:47:30.324994 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m16:47:30.325805 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m16:47:30.325937 [debug] [Thread-3  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m16:47:31.043565 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:c9dec9e0-cd0d-43b0-96d7-198f86eb0381:northamerica-northeast1&page=queryresults
[0m16:47:31.049017 [debug] [Thread-3  ]: finished collecting timing info
[0m16:47:31.050025 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc7c6d47-5536-496a-8d2d-9b359232d835', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058a5eb0>]}
[0m16:47:31.050556 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.75s]
[0m16:47:31.051113 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m16:47:31.052749 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m16:47:31.053344 [info ] [MainThread]: 
[0m16:47:31.053621 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.38 seconds (4.38s).
[0m16:47:31.053871 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:47:31.053998 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m16:47:31.054115 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m16:47:31.065739 [info ] [MainThread]: 
[0m16:47:31.066023 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:47:31.066248 [info ] [MainThread]: 
[0m16:47:31.066418 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:47:31.066714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d4e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105899910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058d1370>]}
[0m16:47:31.066903 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 17:32:05.520192 | 7e75b221-ba1d-4be5-9d9e-bbb8883dfbea ==============================
[0m17:32:05.520198 [info ] [MainThread]: Running with dbt=1.3.0
[0m17:32:05.520559 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m17:32:05.520627 [debug] [MainThread]: Tracking: tracking
[0m17:32:06.480833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a17eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b29700>]}
[0m17:32:06.897941 [debug] [MainThread]: Executing "git --help"
[0m17:32:06.920671 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:32:06.920996 [debug] [MainThread]: STDERR: "b''"
[0m17:32:06.925390 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m17:32:06.926118 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:32:08.209802 [debug] [MainThread]: On debug: select 1 as id
[0m17:32:09.246965 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:b82e15f1-ca96-45a4-b08b-52baa06ce677:northamerica-northeast1&page=queryresults
[0m17:32:09.249006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f56520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f56a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f56670>]}
[0m17:32:09.250028 [debug] [MainThread]: Flushing usage events
[0m17:32:09.491193 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 17:32:16.575570 | dff86e6b-32e7-40ef-9376-705c6471dfdd ==============================
[0m17:32:16.575600 [info ] [MainThread]: Running with dbt=1.3.0
[0m17:32:16.575943 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'resource_types': [], 'which': 'build', 'rpc_method': 'build'}
[0m17:32:16.576026 [debug] [MainThread]: Tracking: tracking
[0m17:32:16.594373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119554310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119554490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119554430>]}
[0m17:32:16.643173 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m17:32:16.643407 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox3/schema.yml
[0m17:32:16.643503 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox3/dbt_sandbox3__cust_orders.sql
[0m17:32:16.651692 [debug] [MainThread]: 1699: static parser successfully parsed dbt_sandbox3/dbt_sandbox3__cust_orders.sql
[0m17:32:16.667479 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m17:32:16.670417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dff86e6b-32e7-40ef-9376-705c6471dfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11973dfa0>]}
[0m17:32:16.675285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dff86e6b-32e7-40ef-9376-705c6471dfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119636cd0>]}
[0m17:32:16.675468 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:32:16.675593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff86e6b-32e7-40ef-9376-705c6471dfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119636f10>]}
[0m17:32:16.676356 [info ] [MainThread]: 
[0m17:32:16.676695 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:32:16.677176 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m17:32:16.677286 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:32:17.792058 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m17:32:17.792254 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:32:17.993083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dff86e6b-32e7-40ef-9376-705c6471dfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11954e070>]}
[0m17:32:17.993674 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:32:17.993881 [info ] [MainThread]: 
[0m17:32:17.998790 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m17:32:17.999052 [info ] [Thread-1  ]: 1 of 6 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m17:32:17.999592 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m17:32:17.999712 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m17:32:17.999839 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m17:32:18.002760 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m17:32:18.003338 [debug] [Thread-1  ]: finished collecting timing info
[0m17:32:18.003461 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m17:32:18.015344 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:32:18.319083 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m17:32:18.319662 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m17:32:19.980254 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:1182dcef-c52a-48a6-8606-b8898118716e:northamerica-northeast1&page=queryresults
[0m17:32:20.006406 [debug] [Thread-1  ]: finished collecting timing info
[0m17:32:20.007102 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dff86e6b-32e7-40ef-9376-705c6471dfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1197e7fa0>]}
[0m17:32:20.007481 [info ] [Thread-1  ]: 1 of 6 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.01s]
[0m17:32:20.007857 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m17:32:20.008502 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:32:20.008703 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m17:32:20.008810 [info ] [Thread-3  ]: 2 of 6 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m17:32:20.008929 [info ] [Thread-4  ]: 3 of 6 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m17:32:20.009376 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:32:20.009774 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m17:32:20.009900 [debug] [Thread-3  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:32:20.010026 [debug] [Thread-4  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m17:32:20.010142 [debug] [Thread-3  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:32:20.010229 [debug] [Thread-4  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m17:32:20.021261 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:32:20.025975 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m17:32:20.026659 [debug] [Thread-3  ]: finished collecting timing info
[0m17:32:20.026788 [debug] [Thread-3  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:32:20.032481 [debug] [Thread-4  ]: finished collecting timing info
[0m17:32:20.036387 [debug] [Thread-3  ]: Writing runtime sql for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m17:32:20.036475 [debug] [Thread-4  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m17:32:20.037818 [debug] [Thread-4  ]: Writing runtime sql for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m17:32:20.038251 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:32:20.038346 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m17:32:20.038442 [debug] [Thread-3  ]: On test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m17:32:20.038526 [debug] [Thread-4  ]: On test.dbt_star.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m17:32:20.968085 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:7403d1a2-c1f1-4cae-b00d-7819cc6ff2c0:northamerica-northeast1&page=queryresults
[0m17:32:20.972853 [debug] [Thread-3  ]: finished collecting timing info
[0m17:32:20.975312 [error] [Thread-3  ]: 2 of 6 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.97s]
[0m17:32:20.976577 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m17:32:21.021552 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:3b7adb23-0554-4b82-bcc4-2cf8857bb215:northamerica-northeast1&page=queryresults
[0m17:32:21.022222 [debug] [Thread-4  ]: finished collecting timing info
[0m17:32:21.022982 [info ] [Thread-4  ]: 3 of 6 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 1.01s]
[0m17:32:21.023489 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m17:32:21.024068 [debug] [Thread-1  ]: Began running node model.dbt_star.my_second_dbt_model
[0m17:32:21.024570 [info ] [Thread-1  ]: 4 of 6 SKIP relation dbt_sandbox16.my_second_dbt_model ......................... [[33mSKIP[0m]
[0m17:32:21.025286 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m17:32:21.025881 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m17:32:21.026088 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m17:32:21.026265 [info ] [Thread-3  ]: 5 of 6 SKIP test not_null_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m17:32:21.026475 [info ] [Thread-4  ]: 6 of 6 SKIP test unique_my_second_dbt_model_id ................................. [[33mSKIP[0m]
[0m17:32:21.026844 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m17:32:21.027173 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m17:32:21.028588 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:32:21.029168 [info ] [MainThread]: 
[0m17:32:21.029429 [info ] [MainThread]: Finished running 1 table model, 4 tests, 1 view model in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m17:32:21.029670 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:32:21.029791 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m17:32:21.029904 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m17:32:21.030018 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m17:32:21.039322 [info ] [MainThread]: 
[0m17:32:21.039549 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m17:32:21.039747 [info ] [MainThread]: 
[0m17:32:21.039909 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m17:32:21.040077 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m17:32:21.040230 [info ] [MainThread]: 
[0m17:32:21.040385 [info ] [MainThread]:   compiled Code at target/compiled/dbt_star/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m17:32:21.040549 [info ] [MainThread]: 
[0m17:32:21.040706 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=3 TOTAL=6
[0m17:32:21.040950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1196d54c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198bd5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198bd250>]}
[0m17:32:21.041146 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 17:33:17.286491 | 5850495f-44f5-4610-bf5e-e5421ea6e27e ==============================
[0m17:33:17.286514 [info ] [MainThread]: Running with dbt=1.3.0
[0m17:33:17.286897 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:33:17.286976 [debug] [MainThread]: Tracking: tracking
[0m17:33:17.301382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1ddc0>]}
[0m17:33:17.354462 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:33:17.354615 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:33:17.354849 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m17:33:17.358487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5850495f-44f5-4610-bf5e-e5421ea6e27e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070b50d0>]}
[0m17:33:17.363669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5850495f-44f5-4610-bf5e-e5421ea6e27e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5c10>]}
[0m17:33:17.363876 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:33:17.364008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5850495f-44f5-4610-bf5e-e5421ea6e27e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5c40>]}
[0m17:33:17.364929 [info ] [MainThread]: 
[0m17:33:17.365478 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:33:17.366239 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m17:33:17.366336 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:33:18.491114 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m17:33:18.491600 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:33:18.702651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5850495f-44f5-4610-bf5e-e5421ea6e27e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1deb0>]}
[0m17:33:18.703957 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:33:18.704386 [info ] [MainThread]: 
[0m17:33:18.709950 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m17:33:18.710355 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m17:33:18.711133 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m17:33:18.711316 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m17:33:18.711525 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m17:33:18.716321 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m17:33:18.717473 [debug] [Thread-1  ]: finished collecting timing info
[0m17:33:18.717651 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m17:33:18.732460 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:33:18.992012 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m17:33:18.992614 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m17:33:20.925441 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:4705391f-4af9-4e80-bc93-ba5b2d2766c8:northamerica-northeast1&page=queryresults
[0m17:33:20.948347 [debug] [Thread-1  ]: finished collecting timing info
[0m17:33:20.949104 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5850495f-44f5-4610-bf5e-e5421ea6e27e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10718d6a0>]}
[0m17:33:20.949483 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.24s]
[0m17:33:20.949857 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m17:33:20.950309 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m17:33:20.950704 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m17:33:20.951356 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m17:33:20.951494 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m17:33:20.951617 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m17:33:20.954459 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m17:33:20.955486 [debug] [Thread-3  ]: finished collecting timing info
[0m17:33:20.955606 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m17:33:20.971224 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m17:33:20.971782 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:33:20.971907 [debug] [Thread-3  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m17:33:21.803381 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:c198753e-3119-49a6-916d-38ff124b1b28:northamerica-northeast1&page=queryresults
[0m17:33:21.807330 [debug] [Thread-3  ]: finished collecting timing info
[0m17:33:21.808375 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5850495f-44f5-4610-bf5e-e5421ea6e27e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712e2e0>]}
[0m17:33:21.808923 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.86s]
[0m17:33:21.809432 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m17:33:21.811118 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:33:21.811808 [info ] [MainThread]: 
[0m17:33:21.812110 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.45 seconds (4.45s).
[0m17:33:21.812373 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:33:21.812499 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m17:33:21.812614 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m17:33:21.824528 [info ] [MainThread]: 
[0m17:33:21.824774 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:33:21.824984 [info ] [MainThread]: 
[0m17:33:21.825149 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:33:21.825399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f1de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc5c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10709fa00>]}
[0m17:33:21.825588 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 17:59:20.657427 | 93251806-a7c3-47d7-bbf4-802b3c4a2cf0 ==============================
[0m17:59:20.657458 [info ] [MainThread]: Running with dbt=1.3.0
[0m17:59:20.657810 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m17:59:20.657899 [debug] [MainThread]: Tracking: tracking
[0m17:59:20.673693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107254820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072549a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107254940>]}
[0m17:59:20.721022 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 2 files added, 0 files changed.
[0m17:59:20.721260 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox3/dbt_sandbox3__customers.sql
[0m17:59:20.721357 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dim_customers.sql
[0m17:59:20.721414 [debug] [MainThread]: Partial parsing: deleted file: dbt_star://models/dbt_sandbox3/dbt_sandbox3__cust_orders.sql
[0m17:59:20.728784 [debug] [MainThread]: 1699: static parser successfully parsed dbt_sandbox3/dbt_sandbox3__customers.sql
[0m17:59:20.735158 [debug] [MainThread]: 1699: static parser successfully parsed dim_customers.sql
[0m17:59:20.743455 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m17:59:20.746427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '93251806-a7c3-47d7-bbf4-802b3c4a2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10745e0d0>]}
[0m17:59:20.752046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '93251806-a7c3-47d7-bbf4-802b3c4a2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10740c1c0>]}
[0m17:59:20.752252 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m17:59:20.752376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93251806-a7c3-47d7-bbf4-802b3c4a2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10740c100>]}
[0m17:59:20.753097 [info ] [MainThread]: 
[0m17:59:20.753432 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:59:20.753931 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m17:59:20.754065 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:59:21.947354 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m17:59:21.947654 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:59:22.155880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '93251806-a7c3-47d7-bbf4-802b3c4a2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107357940>]}
[0m17:59:22.156883 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:59:22.157102 [info ] [MainThread]: 
[0m17:59:22.161044 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m17:59:22.161327 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m17:59:22.161828 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m17:59:22.161962 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m17:59:22.162137 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m17:59:22.166017 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m17:59:22.166776 [debug] [Thread-1  ]: finished collecting timing info
[0m17:59:22.166889 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m17:59:22.182488 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m17:59:22.518216 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m17:59:22.519053 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m17:59:24.481303 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:56cde3b0-5e32-4fe3-b58b-9300f5062055:northamerica-northeast1&page=queryresults
[0m17:59:24.503132 [debug] [Thread-1  ]: finished collecting timing info
[0m17:59:24.503769 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93251806-a7c3-47d7-bbf4-802b3c4a2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074f7d30>]}
[0m17:59:24.504126 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.34s]
[0m17:59:24.504504 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m17:59:24.505115 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m17:59:24.505400 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m17:59:24.505937 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m17:59:24.506057 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m17:59:24.506176 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m17:59:24.511991 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m17:59:24.512638 [debug] [Thread-3  ]: finished collecting timing info
[0m17:59:24.512756 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m17:59:24.530372 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m17:59:24.530934 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m17:59:24.531060 [debug] [Thread-3  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m17:59:25.447783 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:37c3b528-f82b-4d2c-8cca-6914cf518127:northamerica-northeast1&page=queryresults
[0m17:59:25.450891 [debug] [Thread-3  ]: finished collecting timing info
[0m17:59:25.451847 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '93251806-a7c3-47d7-bbf4-802b3c4a2cf0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10757d850>]}
[0m17:59:25.452373 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.95s]
[0m17:59:25.452945 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m17:59:25.454809 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m17:59:25.455458 [info ] [MainThread]: 
[0m17:59:25.455774 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.70 seconds (4.70s).
[0m17:59:25.456048 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:59:25.456186 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m17:59:25.456303 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m17:59:25.467965 [info ] [MainThread]: 
[0m17:59:25.468236 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:59:25.468462 [info ] [MainThread]: 
[0m17:59:25.468631 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:59:25.468884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073d97c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073bbf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10745e400>]}
[0m17:59:25.469087 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 18:23:13.551179 | b1dfb001-da56-4358-86b8-dae40f4c1e8b ==============================
[0m18:23:13.551186 [info ] [MainThread]: Running with dbt=1.3.0
[0m18:23:13.551381 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m18:23:13.551446 [debug] [MainThread]: Tracking: tracking
[0m18:23:13.569016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077d3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077b2e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077d3b50>]}
[0m18:23:13.893199 [debug] [MainThread]: Executing "git --help"
[0m18:23:13.916614 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:23:13.916967 [debug] [MainThread]: STDERR: "b''"
[0m18:23:13.920194 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m18:23:13.920914 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:23:14.349926 [debug] [MainThread]: On debug: select 1 as id
[0m18:23:15.301624 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:ad17b043-cdd1-4cdc-a8df-f6bff62e4350:northamerica-northeast1&page=queryresults
[0m18:23:15.303258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d17d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d17370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aa4f70>]}
[0m18:23:15.303919 [debug] [MainThread]: Flushing usage events
[0m18:23:15.520348 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 18:23:48.669044 | 9e01ed16-f1ac-4293-953f-f3e792dff755 ==============================
[0m18:23:48.669070 [info ] [MainThread]: Running with dbt=1.3.0
[0m18:23:48.669453 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'resource_types': [], 'which': 'build', 'rpc_method': 'build'}
[0m18:23:48.669547 [debug] [MainThread]: Tracking: tracking
[0m18:23:48.688872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11315c520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11315c6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11315c640>]}
[0m18:23:48.734261 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m18:23:48.734481 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/example/dim_customers.sql
[0m18:23:48.734551 [debug] [MainThread]: Partial parsing: deleted file: dbt_star://models/dim_customers.sql
[0m18:23:48.741829 [debug] [MainThread]: 1699: static parser successfully parsed example/dim_customers.sql
[0m18:23:48.754777 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m18:23:48.757793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e01ed16-f1ac-4293-953f-f3e792dff755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b2ee0>]}
[0m18:23:48.763597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e01ed16-f1ac-4293-953f-f3e792dff755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11344f070>]}
[0m18:23:48.763849 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:23:48.763984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e01ed16-f1ac-4293-953f-f3e792dff755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11344f100>]}
[0m18:23:48.764999 [info ] [MainThread]: 
[0m18:23:48.765415 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:23:48.765995 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m18:23:48.766151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:23:49.865154 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m18:23:49.865702 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:23:50.099776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e01ed16-f1ac-4293-953f-f3e792dff755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134262e0>]}
[0m18:23:50.100571 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:23:50.100842 [info ] [MainThread]: 
[0m18:23:50.104843 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m18:23:50.105128 [info ] [Thread-1  ]: 1 of 6 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m18:23:50.105726 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m18:23:50.105873 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m18:23:50.106031 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m18:23:50.109364 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m18:23:50.110069 [debug] [Thread-1  ]: finished collecting timing info
[0m18:23:50.110241 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m18:23:50.121539 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:23:50.366610 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m18:23:50.367508 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m18:23:52.242883 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:3aeb2416-2d03-4281-8430-e7d18fc76701:northamerica-northeast1&page=queryresults
[0m18:23:52.267080 [debug] [Thread-1  ]: finished collecting timing info
[0m18:23:52.267787 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e01ed16-f1ac-4293-953f-f3e792dff755', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135138e0>]}
[0m18:23:52.268166 [info ] [Thread-1  ]: 1 of 6 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.16s]
[0m18:23:52.268562 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m18:23:52.269272 [debug] [Thread-3  ]: Began running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:23:52.269450 [debug] [Thread-4  ]: Began running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m18:23:52.269562 [info ] [Thread-3  ]: 2 of 6 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m18:23:52.269691 [info ] [Thread-4  ]: 3 of 6 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m18:23:52.270199 [debug] [Thread-3  ]: Acquiring new bigquery connection "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:23:52.270652 [debug] [Thread-4  ]: Acquiring new bigquery connection "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m18:23:52.270820 [debug] [Thread-3  ]: Began compiling node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:23:52.270995 [debug] [Thread-4  ]: Began compiling node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m18:23:52.271131 [debug] [Thread-3  ]: Compiling test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:23:52.271224 [debug] [Thread-4  ]: Compiling test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m18:23:52.284840 [debug] [Thread-4  ]: Writing injected SQL for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m18:23:52.290717 [debug] [Thread-3  ]: Writing injected SQL for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:23:52.290848 [debug] [Thread-4  ]: finished collecting timing info
[0m18:23:52.290999 [debug] [Thread-4  ]: Began executing node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m18:23:52.302349 [debug] [Thread-4  ]: Writing runtime sql for node "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"
[0m18:23:52.302646 [debug] [Thread-3  ]: finished collecting timing info
[0m18:23:52.302747 [debug] [Thread-3  ]: Began executing node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:23:52.304266 [debug] [Thread-3  ]: Writing runtime sql for node "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"
[0m18:23:52.304477 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:23:52.304601 [debug] [Thread-4  ]: On test.dbt_star.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with dbt_test__target as (

  select id as unique_field
  from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
  where id is not null

)

select
    unique_field,
    count(*) as n_records

from dbt_test__target
group by unique_field
having count(*) > 1



      
    ) dbt_internal_test
[0m18:23:52.305326 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:23:52.305459 [debug] [Thread-3  ]: On test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id is null



      
    ) dbt_internal_test
[0m18:23:53.192856 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:767fef35-ab09-4603-b2db-6abb4742d59c:northamerica-northeast1&page=queryresults
[0m18:23:53.196081 [debug] [Thread-4  ]: finished collecting timing info
[0m18:23:53.197096 [info ] [Thread-4  ]: 3 of 6 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.93s]
[0m18:23:53.197565 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:a7e1e283-dac7-4dc3-ba48-5e7826af4f84:northamerica-northeast1&page=queryresults
[0m18:23:53.198183 [debug] [Thread-4  ]: Finished running node test.dbt_star.unique_my_first_dbt_model_id.16e066b321
[0m18:23:53.198704 [debug] [Thread-3  ]: finished collecting timing info
[0m18:23:53.199615 [error] [Thread-3  ]: 2 of 6 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.93s]
[0m18:23:53.200026 [debug] [Thread-3  ]: Finished running node test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710
[0m18:23:53.200765 [debug] [Thread-1  ]: Began running node model.dbt_star.my_second_dbt_model
[0m18:23:53.201025 [info ] [Thread-1  ]: 4 of 6 SKIP relation dbt_sandbox16.my_second_dbt_model ......................... [[33mSKIP[0m]
[0m18:23:53.201521 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m18:23:53.202049 [debug] [Thread-4  ]: Began running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m18:23:53.202273 [debug] [Thread-3  ]: Began running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m18:23:53.202423 [info ] [Thread-4  ]: 5 of 6 SKIP test not_null_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m18:23:53.202624 [info ] [Thread-3  ]: 6 of 6 SKIP test unique_my_second_dbt_model_id ................................. [[33mSKIP[0m]
[0m18:23:53.203000 [debug] [Thread-4  ]: Finished running node test.dbt_star.not_null_my_second_dbt_model_id.151b76d778
[0m18:23:53.203413 [debug] [Thread-3  ]: Finished running node test.dbt_star.unique_my_second_dbt_model_id.57a0f8c493
[0m18:23:53.205127 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:23:53.205803 [info ] [MainThread]: 
[0m18:23:53.206070 [info ] [MainThread]: Finished running 1 table model, 4 tests, 1 view model in 0 hours 0 minutes and 4.44 seconds (4.44s).
[0m18:23:53.206285 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:23:53.206390 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m18:23:53.206489 [debug] [MainThread]: Connection 'test.dbt_star.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
[0m18:23:53.206586 [debug] [MainThread]: Connection 'test.dbt_star.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m18:23:53.214834 [info ] [MainThread]: 
[0m18:23:53.215113 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m18:23:53.215320 [info ] [MainThread]: 
[0m18:23:53.215494 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m18:23:53.215683 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m18:23:53.215841 [info ] [MainThread]: 
[0m18:23:53.216011 [info ] [MainThread]:   compiled Code at target/compiled/dbt_star/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m18:23:53.216180 [info ] [MainThread]: 
[0m18:23:53.216336 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=3 TOTAL=6
[0m18:23:53.216618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113426d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134261c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b28b0>]}
[0m18:23:53.216853 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 18:24:19.045462 | 9b943406-51d8-4e84-b69f-a1d94ffc084a ==============================
[0m18:24:19.045498 [info ] [MainThread]: Running with dbt=1.3.0
[0m18:24:19.045880 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:24:19.045965 [debug] [MainThread]: Tracking: tracking
[0m18:24:19.063007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f160>]}
[0m18:24:19.108690 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:24:19.108851 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:24:19.109092 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m18:24:19.112831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b943406-51d8-4e84-b69f-a1d94ffc084a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10880cfd0>]}
[0m18:24:19.117974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b943406-51d8-4e84-b69f-a1d94ffc084a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087db340>]}
[0m18:24:19.118188 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:24:19.118314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b943406-51d8-4e84-b69f-a1d94ffc084a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087db190>]}
[0m18:24:19.119103 [info ] [MainThread]: 
[0m18:24:19.119480 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:24:19.120059 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m18:24:19.120234 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:24:20.269958 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m18:24:20.270563 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:24:20.495547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b943406-51d8-4e84-b69f-a1d94ffc084a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f7430>]}
[0m18:24:20.496785 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:24:20.497188 [info ] [MainThread]: 
[0m18:24:20.503131 [debug] [Thread-1  ]: Began running node model.dbt_star.my_first_dbt_model
[0m18:24:20.503589 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m18:24:20.504472 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m18:24:20.504665 [debug] [Thread-1  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m18:24:20.504861 [debug] [Thread-1  ]: Compiling model.dbt_star.my_first_dbt_model
[0m18:24:20.509387 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m18:24:20.510193 [debug] [Thread-1  ]: finished collecting timing info
[0m18:24:20.510386 [debug] [Thread-1  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m18:24:20.523272 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:24:20.786279 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m18:24:20.786870 [debug] [Thread-1  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m18:24:22.601697 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:6302114d-1795-42c2-898d-e4ca401a0689:northamerica-northeast1&page=queryresults
[0m18:24:22.625716 [debug] [Thread-1  ]: finished collecting timing info
[0m18:24:22.626438 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b943406-51d8-4e84-b69f-a1d94ffc084a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f160>]}
[0m18:24:22.626806 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.12s]
[0m18:24:22.627192 [debug] [Thread-1  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m18:24:22.627690 [debug] [Thread-3  ]: Began running node model.dbt_star.my_second_dbt_model
[0m18:24:22.628030 [info ] [Thread-3  ]: 2 of 2 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m18:24:22.628732 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m18:24:22.628861 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m18:24:22.628978 [debug] [Thread-3  ]: Compiling model.dbt_star.my_second_dbt_model
[0m18:24:22.631796 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m18:24:22.632439 [debug] [Thread-3  ]: finished collecting timing info
[0m18:24:22.632556 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m18:24:22.648443 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m18:24:22.648999 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:24:22.649140 [debug] [Thread-3  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m18:24:23.485811 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:986a718d-cc07-4387-afcc-cf0e2b98dfc3:northamerica-northeast1&page=queryresults
[0m18:24:23.487786 [debug] [Thread-3  ]: finished collecting timing info
[0m18:24:23.488400 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b943406-51d8-4e84-b69f-a1d94ffc084a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10893ef40>]}
[0m18:24:23.488792 [info ] [Thread-3  ]: 2 of 2 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.86s]
[0m18:24:23.489195 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m18:24:23.490594 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:24:23.491089 [info ] [MainThread]: 
[0m18:24:23.491292 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 4.37 seconds (4.37s).
[0m18:24:23.491466 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:24:23.491549 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m18:24:23.491626 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m18:24:23.499734 [info ] [MainThread]: 
[0m18:24:23.499908 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:24:23.500075 [info ] [MainThread]: 
[0m18:24:23.500206 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:24:23.500401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108695d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10893ef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108964580>]}
[0m18:24:23.500544 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 18:56:57.503145 | b21be700-56ca-4dc0-9b68-e8e37ff23bd2 ==============================
[0m18:56:57.503164 [info ] [MainThread]: Running with dbt=1.3.0
[0m18:56:57.503505 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:56:57.503595 [debug] [MainThread]: Tracking: tracking
[0m18:56:57.515284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052d5580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052d5700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052d56a0>]}
[0m18:56:57.557725 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m18:56:57.557991 [debug] [MainThread]: Partial parsing: updated file: dbt_star://models/example/dim_customers.sql
[0m18:56:57.565531 [debug] [MainThread]: 1699: static parser successfully parsed example/dim_customers.sql
[0m18:56:57.578662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.example.example

[0m18:56:57.581721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054f1f70>]}
[0m18:56:57.586535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10548e1c0>]}
[0m18:56:57.586732 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:56:57.586872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10548e100>]}
[0m18:56:57.587623 [info ] [MainThread]: 
[0m18:56:57.587987 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:56:57.588551 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m18:56:57.588709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:56:58.759870 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m18:56:58.760217 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:56:58.965508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105465ac0>]}
[0m18:56:58.966072 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:56:58.966265 [info ] [MainThread]: 
[0m18:56:58.969836 [debug] [Thread-1  ]: Began running node model.dbt_star.dim_customers
[0m18:56:58.970008 [debug] [Thread-2  ]: Began running node model.dbt_star.my_first_dbt_model
[0m18:56:58.970184 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_sandbox16.dim_customers ....................... [RUN]
[0m18:56:58.970347 [info ] [Thread-2  ]: 2 of 3 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m18:56:58.970801 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.dim_customers"
[0m18:56:58.971286 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m18:56:58.971416 [debug] [Thread-1  ]: Began compiling node model.dbt_star.dim_customers
[0m18:56:58.971502 [debug] [Thread-2  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m18:56:58.971616 [debug] [Thread-1  ]: Compiling model.dbt_star.dim_customers
[0m18:56:58.971825 [debug] [Thread-2  ]: Compiling model.dbt_star.my_first_dbt_model
[0m18:56:58.974363 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.dim_customers"
[0m18:56:58.976457 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m18:56:58.977240 [debug] [Thread-2  ]: finished collecting timing info
[0m18:56:58.977369 [debug] [Thread-2  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m18:56:58.983726 [debug] [Thread-1  ]: finished collecting timing info
[0m18:56:58.987997 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:56:58.988125 [debug] [Thread-1  ]: Began executing node model.dbt_star.dim_customers
[0m18:56:59.003805 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.dim_customers"
[0m18:56:59.004534 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:56:59.004663 [debug] [Thread-1  ]: On model.dbt_star.dim_customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dim_customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dim_customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m18:56:59.258452 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m18:56:59.260890 [debug] [Thread-2  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m18:57:00.920399 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:1aa9fa2f-41fb-4069-810c-09261dc4deb5:northamerica-northeast1&page=queryresults
[0m18:57:00.947048 [debug] [Thread-2  ]: finished collecting timing info
[0m18:57:00.947848 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054b25e0>]}
[0m18:57:00.948224 [info ] [Thread-2  ]: 2 of 3 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 1.98s]
[0m18:57:00.948646 [debug] [Thread-2  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m18:57:00.949071 [debug] [Thread-4  ]: Began running node model.dbt_star.my_second_dbt_model
[0m18:57:00.949299 [info ] [Thread-4  ]: 3 of 3 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m18:57:00.949809 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m18:57:00.949919 [debug] [Thread-4  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m18:57:00.950025 [debug] [Thread-4  ]: Compiling model.dbt_star.my_second_dbt_model
[0m18:57:00.952810 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m18:57:00.953878 [debug] [Thread-4  ]: finished collecting timing info
[0m18:57:00.954000 [debug] [Thread-4  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m18:57:00.969774 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m18:57:00.970334 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:57:00.970460 [debug] [Thread-4  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m18:57:01.524237 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:14b64d8f-cd24-4cda-a269-033af8e887f5:northamerica-northeast1&page=queryresults
[0m18:57:01.527651 [debug] [Thread-4  ]: finished collecting timing info
[0m18:57:01.528707 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058165e0>]}
[0m18:57:01.529266 [info ] [Thread-4  ]: 3 of 3 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.58s]
[0m18:57:01.529871 [debug] [Thread-4  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m18:57:03.206440 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:389df5ba-9f88-434f-91ad-cbc2f89a14c7:northamerica-northeast1&page=queryresults
[0m18:57:03.210211 [debug] [Thread-1  ]: finished collecting timing info
[0m18:57:03.211203 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b21be700-56ca-4dc0-9b68-e8e37ff23bd2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056dad30>]}
[0m18:57:03.211717 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_sandbox16.dim_customers .................. [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 4.24s]
[0m18:57:03.212259 [debug] [Thread-1  ]: Finished running node model.dbt_star.dim_customers
[0m18:57:03.214229 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:57:03.214953 [info ] [MainThread]: 
[0m18:57:03.215220 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 5.63 seconds (5.63s).
[0m18:57:03.215471 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:57:03.215597 [debug] [MainThread]: Connection 'model.dbt_star.dim_customers' was properly closed.
[0m18:57:03.215713 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m18:57:03.215823 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m18:57:03.228169 [info ] [MainThread]: 
[0m18:57:03.228503 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:57:03.228790 [info ] [MainThread]: 
[0m18:57:03.228991 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m18:57:03.229245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105444490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054646a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056dc070>]}
[0m18:57:03.229442 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 18:59:26.258455 | 103b944b-4a29-4097-900e-24d8fe9111ee ==============================
[0m18:59:26.258486 [info ] [MainThread]: Running with dbt=1.3.0
[0m18:59:26.258921 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m18:59:26.259005 [debug] [MainThread]: Tracking: tracking
[0m18:59:26.277534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761d370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761d4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761d490>]}
[0m18:59:26.298302 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m18:59:26.298529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107647160>]}
[0m18:59:26.321320 [debug] [MainThread]: Parsing macros/etc.sql
[0m18:59:26.322569 [debug] [MainThread]: Parsing macros/catalog.sql
[0m18:59:26.326354 [debug] [MainThread]: Parsing macros/adapters.sql
[0m18:59:26.337768 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m18:59:26.339103 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m18:59:26.340488 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m18:59:26.344334 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m18:59:26.345645 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m18:59:26.354956 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m18:59:26.355866 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m18:59:26.356044 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m18:59:26.356344 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m18:59:26.356844 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m18:59:26.357012 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m18:59:26.357275 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m18:59:26.357573 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m18:59:26.358045 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m18:59:26.358630 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m18:59:26.358860 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m18:59:26.359087 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m18:59:26.359327 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m18:59:26.359557 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m18:59:26.359754 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m18:59:26.360477 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m18:59:26.360715 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m18:59:26.361090 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m18:59:26.361370 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m18:59:26.362608 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m18:59:26.364490 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m18:59:26.365566 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m18:59:26.366362 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m18:59:26.374418 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m18:59:26.381596 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m18:59:26.388176 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m18:59:26.390442 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m18:59:26.391305 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m18:59:26.392171 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m18:59:26.396262 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m18:59:26.405099 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m18:59:26.405837 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m18:59:26.409162 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m18:59:26.414524 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m18:59:26.424130 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m18:59:26.426953 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m18:59:26.428648 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m18:59:26.431457 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m18:59:26.432061 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m18:59:26.433720 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m18:59:26.434805 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m18:59:26.438397 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m18:59:26.448863 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m18:59:26.449565 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m18:59:26.450751 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m18:59:26.451496 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m18:59:26.451917 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m18:59:26.452295 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m18:59:26.452611 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m18:59:26.453269 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m18:59:26.455889 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m18:59:26.460276 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m18:59:26.460675 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m18:59:26.461261 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m18:59:26.461787 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m18:59:26.462272 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m18:59:26.462881 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m18:59:26.463267 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m18:59:26.463745 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m18:59:26.464337 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m18:59:26.465483 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m18:59:26.466056 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m18:59:26.466553 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m18:59:26.467036 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m18:59:26.467508 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m18:59:26.467924 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m18:59:26.468419 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m18:59:26.468839 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m18:59:26.471996 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m18:59:26.472477 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m18:59:26.472895 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m18:59:26.473724 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m18:59:26.474799 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m18:59:26.475267 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m18:59:26.475956 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m18:59:26.476433 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m18:59:26.477409 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m18:59:26.478942 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m18:59:26.480241 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m18:59:26.487722 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m18:59:26.488653 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m18:59:26.495238 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m18:59:26.497336 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m18:59:26.500877 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m18:59:26.505728 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m18:59:26.508738 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m18:59:26.639384 [debug] [MainThread]: 1699: static parser successfully parsed dbt_sandbox3/dbt_sandbox3__customers.sql
[0m18:59:26.645519 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m18:59:26.646794 [debug] [MainThread]: 1699: static parser successfully parsed example/dim_customers.sql
[0m18:59:26.647995 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m18:59:26.716753 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_sandbox3.dbt_sandbox3
- models.example.example

[0m18:59:26.719733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107764820>]}
[0m18:59:26.724218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077949a0>]}
[0m18:59:26.724401 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m18:59:26.724536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b92e0>]}
[0m18:59:26.725422 [info ] [MainThread]: 
[0m18:59:26.725917 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:59:26.726543 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m18:59:26.726636 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:59:27.846020 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m18:59:27.846230 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:59:28.064481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077643a0>]}
[0m18:59:28.065823 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:59:28.066229 [info ] [MainThread]: 
[0m18:59:28.071279 [debug] [Thread-1  ]: Began running node model.dbt_star.dbt_sandbox3__customers
[0m18:59:28.071637 [debug] [Thread-2  ]: Began running node model.dbt_star.dim_customers
[0m18:59:28.071806 [debug] [Thread-3  ]: Began running node model.dbt_star.my_first_dbt_model
[0m18:59:28.072079 [info ] [Thread-1  ]: 1 of 4 START sql table model dbt_sandbox16.dbt_sandbox3__customers ............. [RUN]
[0m18:59:28.072358 [info ] [Thread-2  ]: 2 of 4 START sql table model dbt_sandbox16.dim_customers ....................... [RUN]
[0m18:59:28.072583 [info ] [Thread-3  ]: 3 of 4 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m18:59:28.073325 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.dbt_sandbox3__customers"
[0m18:59:28.074184 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.dbt_star.dim_customers"
[0m18:59:28.074759 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m18:59:28.074917 [debug] [Thread-1  ]: Began compiling node model.dbt_star.dbt_sandbox3__customers
[0m18:59:28.075072 [debug] [Thread-2  ]: Began compiling node model.dbt_star.dim_customers
[0m18:59:28.075210 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m18:59:28.075398 [debug] [Thread-1  ]: Compiling model.dbt_star.dbt_sandbox3__customers
[0m18:59:28.075530 [debug] [Thread-2  ]: Compiling model.dbt_star.dim_customers
[0m18:59:28.075742 [debug] [Thread-3  ]: Compiling model.dbt_star.my_first_dbt_model
[0m18:59:28.079459 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.dbt_sandbox3__customers"
[0m18:59:28.082200 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_star.dim_customers"
[0m18:59:28.088134 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m18:59:28.088643 [debug] [Thread-2  ]: finished collecting timing info
[0m18:59:28.088895 [debug] [Thread-2  ]: Began executing node model.dbt_star.dim_customers
[0m18:59:28.101520 [debug] [Thread-3  ]: finished collecting timing info
[0m18:59:28.105104 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m18:59:28.105286 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m18:59:28.105384 [debug] [Thread-1  ]: finished collecting timing info
[0m18:59:28.107008 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m18:59:28.107444 [debug] [Thread-1  ]: Began executing node model.dbt_star.dbt_sandbox3__customers
[0m18:59:28.125110 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.dbt_sandbox3__customers"
[0m18:59:28.126319 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:59:28.126449 [debug] [Thread-1  ]: On model.dbt_star.dbt_sandbox3__customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dbt_sandbox3__customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dbt_sandbox3__customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m18:59:28.348255 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_star.dim_customers"
[0m18:59:28.349746 [debug] [Thread-2  ]: On model.dbt_star.dim_customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dim_customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dim_customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m18:59:28.366124 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m18:59:28.366939 [debug] [Thread-3  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m18:59:30.046667 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:7d141619-12ca-4c3b-9e24-5df6cb10e7eb:northamerica-northeast1&page=queryresults
[0m18:59:30.063531 [debug] [Thread-3  ]: finished collecting timing info
[0m18:59:30.064033 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077af760>]}
[0m18:59:30.064306 [info ] [Thread-3  ]: 3 of 4 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 1.99s]
[0m18:59:30.064714 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m18:59:30.065145 [debug] [Thread-4  ]: Began running node model.dbt_star.my_second_dbt_model
[0m18:59:30.065364 [info ] [Thread-4  ]: 4 of 4 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m18:59:30.065849 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m18:59:30.065954 [debug] [Thread-4  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m18:59:30.066050 [debug] [Thread-4  ]: Compiling model.dbt_star.my_second_dbt_model
[0m18:59:30.068431 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m18:59:30.069129 [debug] [Thread-4  ]: finished collecting timing info
[0m18:59:30.069305 [debug] [Thread-4  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m18:59:30.085147 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m18:59:30.085840 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m18:59:30.086020 [debug] [Thread-4  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m18:59:30.936688 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:71d337fd-65f6-4de1-aefe-801c00c990c5:northamerica-northeast1&page=queryresults
[0m18:59:30.939822 [debug] [Thread-4  ]: finished collecting timing info
[0m18:59:30.940785 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d19040>]}
[0m18:59:30.941318 [info ] [Thread-4  ]: 4 of 4 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.88s]
[0m18:59:30.941858 [debug] [Thread-4  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m18:59:32.240231 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:b116f227-fff4-4e4c-b73c-be03207e2122:northamerica-northeast1&page=queryresults
[0m18:59:32.241241 [debug] [Thread-1  ]: finished collecting timing info
[0m18:59:32.241652 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077af340>]}
[0m18:59:32.241896 [info ] [Thread-1  ]: 1 of 4 OK created sql table model dbt_sandbox16.dbt_sandbox3__customers ........ [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 4.17s]
[0m18:59:32.242147 [debug] [Thread-1  ]: Finished running node model.dbt_star.dbt_sandbox3__customers
[0m18:59:32.508639 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:d67ac4e2-2824-45da-b3d4-7b57547d329c:northamerica-northeast1&page=queryresults
[0m18:59:32.513052 [debug] [Thread-2  ]: finished collecting timing info
[0m18:59:32.514130 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '103b944b-4a29-4097-900e-24d8fe9111ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077afe20>]}
[0m18:59:32.514660 [info ] [Thread-2  ]: 2 of 4 OK created sql table model dbt_sandbox16.dim_customers .................. [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 4.44s]
[0m18:59:32.515236 [debug] [Thread-2  ]: Finished running node model.dbt_star.dim_customers
[0m18:59:32.517232 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m18:59:32.517964 [info ] [MainThread]: 
[0m18:59:32.518247 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 5.79 seconds (5.79s).
[0m18:59:32.518494 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:59:32.518627 [debug] [MainThread]: Connection 'model.dbt_star.dbt_sandbox3__customers' was properly closed.
[0m18:59:32.518745 [debug] [MainThread]: Connection 'model.dbt_star.dim_customers' was properly closed.
[0m18:59:32.518859 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m18:59:32.518972 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m18:59:32.530175 [info ] [MainThread]: 
[0m18:59:32.530415 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:59:32.530715 [info ] [MainThread]: 
[0m18:59:32.531090 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m18:59:32.531360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107764820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074f4370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d25ca0>]}
[0m18:59:32.531557 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 19:01:07.523087 | 2b4dcbc9-17b9-428b-9479-1a47e23c9910 ==============================
[0m19:01:07.523092 [info ] [MainThread]: Running with dbt=1.3.0
[0m19:01:07.523291 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'config_dir': False, 'which': 'debug', 'indirect_selection': 'eager'}
[0m19:01:07.523354 [debug] [MainThread]: Tracking: tracking
[0m19:01:07.541376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107edff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ebee20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107edfb50>]}
[0m19:01:07.866811 [debug] [MainThread]: Executing "git --help"
[0m19:01:07.890317 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:01:07.890771 [debug] [MainThread]: STDERR: "b''"
[0m19:01:07.895528 [debug] [MainThread]: Acquiring new bigquery connection "debug"
[0m19:01:07.896161 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:01:08.328965 [debug] [MainThread]: On debug: select 1 as id
[0m19:01:09.222827 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:9267c627-6576-403d-bc27-91d0fa62a4cc:northamerica-northeast1&page=queryresults
[0m19:01:09.223172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109433be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094332b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109433d90>]}
[0m19:01:09.223376 [debug] [MainThread]: Flushing usage events
[0m19:01:09.457283 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-11-23 19:01:14.220036 | bbf14846-4ffc-48f9-9ca5-321e0f20a210 ==============================
[0m19:01:14.220053 [info ] [MainThread]: Running with dbt=1.3.0
[0m19:01:14.220385 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:01:14.220459 [debug] [MainThread]: Tracking: tracking
[0m19:01:14.239316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070183a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107018520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070184c0>]}
[0m19:01:14.260796 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:01:14.261027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10703b670>]}
[0m19:01:14.285051 [debug] [MainThread]: Parsing macros/etc.sql
[0m19:01:14.286315 [debug] [MainThread]: Parsing macros/catalog.sql
[0m19:01:14.290248 [debug] [MainThread]: Parsing macros/adapters.sql
[0m19:01:14.301487 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m19:01:14.302751 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m19:01:14.304130 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m19:01:14.308109 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m19:01:14.309538 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m19:01:14.318471 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m19:01:14.319258 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m19:01:14.319430 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m19:01:14.319724 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m19:01:14.320215 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m19:01:14.320376 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m19:01:14.320633 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m19:01:14.320939 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m19:01:14.321415 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m19:01:14.321989 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m19:01:14.322215 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m19:01:14.322436 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m19:01:14.322675 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m19:01:14.322899 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m19:01:14.323090 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m19:01:14.323813 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m19:01:14.324050 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m19:01:14.324418 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m19:01:14.324684 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m19:01:14.325920 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m19:01:14.327768 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m19:01:14.328834 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m19:01:14.329621 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m19:01:14.337744 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m19:01:14.345078 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m19:01:14.351646 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m19:01:14.353881 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m19:01:14.354770 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m19:01:14.355665 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m19:01:14.359668 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m19:01:14.368284 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m19:01:14.369010 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m19:01:14.372270 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m19:01:14.377508 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m19:01:14.386859 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m19:01:14.389671 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m19:01:14.391330 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m19:01:14.394062 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m19:01:14.394657 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m19:01:14.396274 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m19:01:14.397333 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m19:01:14.400836 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m19:01:14.410882 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m19:01:14.411605 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m19:01:14.412800 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m19:01:14.413548 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m19:01:14.413973 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m19:01:14.414350 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m19:01:14.414667 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m19:01:14.415332 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m19:01:14.418090 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m19:01:14.422486 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m19:01:14.422912 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m19:01:14.423508 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m19:01:14.423969 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m19:01:14.424414 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m19:01:14.425025 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m19:01:14.425407 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m19:01:14.425896 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m19:01:14.426498 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m19:01:14.427674 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m19:01:14.428281 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m19:01:14.428797 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m19:01:14.429331 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m19:01:14.429836 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m19:01:14.430392 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m19:01:14.430952 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m19:01:14.431391 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m19:01:14.434674 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m19:01:14.435185 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m19:01:14.435630 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m19:01:14.436483 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m19:01:14.437575 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m19:01:14.438056 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m19:01:14.438776 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m19:01:14.439281 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m19:01:14.440296 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m19:01:14.441852 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m19:01:14.443178 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m19:01:14.450742 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m19:01:14.451676 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m19:01:14.458346 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m19:01:14.460496 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m19:01:14.464087 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m19:01:14.468986 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m19:01:14.472044 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m19:01:14.602930 [debug] [MainThread]: 1699: static parser successfully parsed dbt_sandbox3/dbt_sandbox3__customers.sql
[0m19:01:14.609051 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m19:01:14.610310 [debug] [MainThread]: 1699: static parser successfully parsed example/dim_customers.sql
[0m19:01:14.611513 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m19:01:14.679299 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.example.example
- models.dbt_sandbox3.dbt_sandbox3

[0m19:01:14.682314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c6520>]}
[0m19:01:14.686846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c6460>]}
[0m19:01:14.687049 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m19:01:14.687180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106faacd0>]}
[0m19:01:14.687983 [info ] [MainThread]: 
[0m19:01:14.688435 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:01:14.689135 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m19:01:14.689280 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:15.742005 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m19:01:15.742563 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:01:15.984999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10707c6d0>]}
[0m19:01:15.986444 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:01:15.986853 [info ] [MainThread]: 
[0m19:01:15.993669 [debug] [Thread-1  ]: Began running node model.dbt_star.dbt_sandbox3__customers
[0m19:01:15.993970 [debug] [Thread-2  ]: Began running node model.dbt_star.dim_customers
[0m19:01:15.994143 [debug] [Thread-3  ]: Began running node model.dbt_star.my_first_dbt_model
[0m19:01:15.994475 [info ] [Thread-1  ]: 1 of 4 START sql table model dbt_sandbox16.dbt_sandbox3__customers ............. [RUN]
[0m19:01:15.994770 [info ] [Thread-2  ]: 2 of 4 START sql table model dbt_sandbox16.dim_customers ....................... [RUN]
[0m19:01:15.994997 [info ] [Thread-3  ]: 3 of 4 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m19:01:15.995803 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.dbt_sandbox3__customers"
[0m19:01:15.996359 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.dbt_star.dim_customers"
[0m19:01:15.996892 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m19:01:15.997043 [debug] [Thread-1  ]: Began compiling node model.dbt_star.dbt_sandbox3__customers
[0m19:01:15.997164 [debug] [Thread-2  ]: Began compiling node model.dbt_star.dim_customers
[0m19:01:15.997278 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m19:01:15.997464 [debug] [Thread-1  ]: Compiling model.dbt_star.dbt_sandbox3__customers
[0m19:01:15.997578 [debug] [Thread-2  ]: Compiling model.dbt_star.dim_customers
[0m19:01:15.997684 [debug] [Thread-3  ]: Compiling model.dbt_star.my_first_dbt_model
[0m19:01:16.001768 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.dbt_sandbox3__customers"
[0m19:01:16.004833 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_star.dim_customers"
[0m19:01:16.010432 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m19:01:16.010824 [debug] [Thread-1  ]: finished collecting timing info
[0m19:01:16.011014 [debug] [Thread-1  ]: Began executing node model.dbt_star.dbt_sandbox3__customers
[0m19:01:16.023176 [debug] [Thread-3  ]: finished collecting timing info
[0m19:01:16.026562 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:01:16.026721 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m19:01:16.027163 [debug] [Thread-2  ]: finished collecting timing info
[0m19:01:16.028526 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:01:16.028932 [debug] [Thread-2  ]: Began executing node model.dbt_star.dim_customers
[0m19:01:16.030316 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:01:16.322976 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m19:01:16.324115 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_star.dim_customers"
[0m19:01:16.324874 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.dbt_sandbox3__customers"
[0m19:01:16.325440 [debug] [Thread-2  ]: On model.dbt_star.dim_customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dim_customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dim_customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:01:16.325555 [debug] [Thread-1  ]: On model.dbt_star.dbt_sandbox3__customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dbt_sandbox3__customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dbt_sandbox3__customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:01:16.325982 [debug] [Thread-3  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m19:01:18.080182 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:7ec196b7-e586-41e1-b8e5-fc589b8ff77f:northamerica-northeast1&page=queryresults
[0m19:01:18.101210 [debug] [Thread-3  ]: finished collecting timing info
[0m19:01:18.101799 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10719ca00>]}
[0m19:01:18.102105 [info ] [Thread-3  ]: 3 of 4 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.11s]
[0m19:01:18.102438 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m19:01:18.102770 [debug] [Thread-4  ]: Began running node model.dbt_star.my_second_dbt_model
[0m19:01:18.103009 [info ] [Thread-4  ]: 4 of 4 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m19:01:18.103561 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m19:01:18.103682 [debug] [Thread-4  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m19:01:18.103800 [debug] [Thread-4  ]: Compiling model.dbt_star.my_second_dbt_model
[0m19:01:18.106555 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m19:01:18.107314 [debug] [Thread-4  ]: finished collecting timing info
[0m19:01:18.107438 [debug] [Thread-4  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m19:01:18.124860 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m19:01:18.125604 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:01:18.125812 [debug] [Thread-4  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m19:01:19.066157 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:70b67123-4e28-4a42-8870-38a905a4345e:northamerica-northeast1&page=queryresults
[0m19:01:19.070788 [debug] [Thread-4  ]: finished collecting timing info
[0m19:01:19.071974 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10715d790>]}
[0m19:01:19.072610 [info ] [Thread-4  ]: 4 of 4 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.97s]
[0m19:01:19.073184 [debug] [Thread-4  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m19:01:20.010093 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:f1538276-7775-47a8-be51-0c78792bcd0f:northamerica-northeast1&page=queryresults
[0m19:01:20.014215 [debug] [Thread-1  ]: finished collecting timing info
[0m19:01:20.015316 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107214250>]}
[0m19:01:20.015887 [info ] [Thread-1  ]: 1 of 4 OK created sql table model dbt_sandbox16.dbt_sandbox3__customers ........ [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 4.02s]
[0m19:01:20.016447 [debug] [Thread-1  ]: Finished running node model.dbt_star.dbt_sandbox3__customers
[0m19:01:20.287081 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:d729d3ce-408d-47b4-9f7f-701fc28678e5:northamerica-northeast1&page=queryresults
[0m19:01:20.293751 [debug] [Thread-2  ]: finished collecting timing info
[0m19:01:20.294731 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bbf14846-4ffc-48f9-9ca5-321e0f20a210', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107308b50>]}
[0m19:01:20.295210 [info ] [Thread-2  ]: 2 of 4 OK created sql table model dbt_sandbox16.dim_customers .................. [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 4.30s]
[0m19:01:20.295638 [debug] [Thread-2  ]: Finished running node model.dbt_star.dim_customers
[0m19:01:20.297237 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:01:20.297800 [info ] [MainThread]: 
[0m19:01:20.298012 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 5.61 seconds (5.61s).
[0m19:01:20.298207 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:01:20.298298 [debug] [MainThread]: Connection 'model.dbt_star.dbt_sandbox3__customers' was properly closed.
[0m19:01:20.298383 [debug] [MainThread]: Connection 'model.dbt_star.dim_customers' was properly closed.
[0m19:01:20.298468 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m19:01:20.298552 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m19:01:20.306985 [info ] [MainThread]: 
[0m19:01:20.307283 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:01:20.307489 [info ] [MainThread]: 
[0m19:01:20.307644 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m19:01:20.307894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10719f160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c7d30>]}
[0m19:01:20.308113 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 19:04:19.488024 | b97a96db-1766-466c-a58d-3d3ce13d99c5 ==============================
[0m19:04:19.488053 [info ] [MainThread]: Running with dbt=1.3.0
[0m19:04:19.488426 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:04:19.488508 [debug] [MainThread]: Tracking: tracking
[0m19:04:19.507211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759d400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759d580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759d520>]}
[0m19:04:19.550219 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 0 files changed.
[0m19:04:19.550441 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox4/dbt_sandbox4__customers.sql
[0m19:04:19.550559 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox4/schema.yml
[0m19:04:19.550626 [debug] [MainThread]: Partial parsing: deleted file: dbt_star://models/dbt_sandbox3/dbt_sandbox3__customers.sql
[0m19:04:19.557819 [debug] [MainThread]: 1699: static parser successfully parsed dbt_sandbox4/dbt_sandbox4__customers.sql
[0m19:04:19.573355 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.example.example
- models.dbt_sandbox3.dbt_sandbox3

[0m19:04:19.576298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107724af0>]}
[0m19:04:19.581020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e7670>]}
[0m19:04:19.581262 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m19:04:19.581418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e7730>]}
[0m19:04:19.582486 [info ] [MainThread]: 
[0m19:04:19.582932 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:04:19.583501 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m19:04:19.583631 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:04:20.748218 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m19:04:20.748729 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:04:20.992083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076fdbb0>]}
[0m19:04:20.993352 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:04:20.993689 [info ] [MainThread]: 
[0m19:04:20.999381 [debug] [Thread-1  ]: Began running node model.dbt_star.dbt_sandbox4__customers
[0m19:04:20.999636 [debug] [Thread-2  ]: Began running node model.dbt_star.dim_customers
[0m19:04:20.999778 [debug] [Thread-3  ]: Began running node model.dbt_star.my_first_dbt_model
[0m19:04:21.000094 [info ] [Thread-1  ]: 1 of 4 START sql table model dbt_sandbox16.dbt_sandbox4__customers ............. [RUN]
[0m19:04:21.000336 [info ] [Thread-2  ]: 2 of 4 START sql table model dbt_sandbox16.dim_customers ....................... [RUN]
[0m19:04:21.000519 [info ] [Thread-3  ]: 3 of 4 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m19:04:21.001324 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.dbt_sandbox4__customers"
[0m19:04:21.001868 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.dbt_star.dim_customers"
[0m19:04:21.002413 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m19:04:21.002565 [debug] [Thread-1  ]: Began compiling node model.dbt_star.dbt_sandbox4__customers
[0m19:04:21.002685 [debug] [Thread-2  ]: Began compiling node model.dbt_star.dim_customers
[0m19:04:21.002794 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m19:04:21.002988 [debug] [Thread-1  ]: Compiling model.dbt_star.dbt_sandbox4__customers
[0m19:04:21.003102 [debug] [Thread-2  ]: Compiling model.dbt_star.dim_customers
[0m19:04:21.003205 [debug] [Thread-3  ]: Compiling model.dbt_star.my_first_dbt_model
[0m19:04:21.006705 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.dbt_sandbox4__customers"
[0m19:04:21.009562 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_star.dim_customers"
[0m19:04:21.015057 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m19:04:21.015462 [debug] [Thread-2  ]: finished collecting timing info
[0m19:04:21.015580 [debug] [Thread-2  ]: Began executing node model.dbt_star.dim_customers
[0m19:04:21.021748 [debug] [Thread-3  ]: finished collecting timing info
[0m19:04:21.021876 [debug] [Thread-1  ]: finished collecting timing info
[0m19:04:21.021990 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m19:04:21.030436 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:04:21.030646 [debug] [Thread-1  ]: Began executing node model.dbt_star.dbt_sandbox4__customers
[0m19:04:21.031965 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:04:21.049091 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.dbt_sandbox4__customers"
[0m19:04:21.050127 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:04:21.050234 [debug] [Thread-1  ]: On model.dbt_star.dbt_sandbox4__customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dbt_sandbox4__customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dbt_sandbox4__customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:04:21.260545 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m19:04:21.261629 [debug] [Thread-3  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m19:04:21.277126 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_star.dim_customers"
[0m19:04:21.277874 [debug] [Thread-2  ]: On model.dbt_star.dim_customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dim_customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dim_customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:04:22.896272 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:dbb025fb-9545-4382-ae63-9b3fc84e72bd:northamerica-northeast1&page=queryresults
[0m19:04:22.920382 [debug] [Thread-3  ]: finished collecting timing info
[0m19:04:22.920972 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10786d550>]}
[0m19:04:22.921326 [info ] [Thread-3  ]: 3 of 4 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 1.92s]
[0m19:04:22.921689 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m19:04:22.922036 [debug] [Thread-4  ]: Began running node model.dbt_star.my_second_dbt_model
[0m19:04:22.922220 [info ] [Thread-4  ]: 4 of 4 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m19:04:22.922693 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m19:04:22.922806 [debug] [Thread-4  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m19:04:22.922907 [debug] [Thread-4  ]: Compiling model.dbt_star.my_second_dbt_model
[0m19:04:22.925365 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m19:04:22.926061 [debug] [Thread-4  ]: finished collecting timing info
[0m19:04:22.926165 [debug] [Thread-4  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m19:04:22.942609 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m19:04:22.943312 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:04:22.943456 [debug] [Thread-4  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m19:04:23.813546 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:c90506a1-77b1-44c7-a671-ee57d5ad351d:northamerica-northeast1&page=queryresults
[0m19:04:23.817948 [debug] [Thread-4  ]: finished collecting timing info
[0m19:04:23.819232 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e03df0>]}
[0m19:04:23.819891 [info ] [Thread-4  ]: 4 of 4 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.90s]
[0m19:04:23.820445 [debug] [Thread-4  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m19:04:24.754437 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:f3536c8c-ba08-4960-b4d3-2f7bf894b43f:northamerica-northeast1&page=queryresults
[0m19:04:24.760147 [debug] [Thread-1  ]: finished collecting timing info
[0m19:04:24.761017 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10771cc10>]}
[0m19:04:24.762009 [info ] [Thread-1  ]: 1 of 4 OK created sql table model dbt_sandbox16.dbt_sandbox4__customers ........ [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 3.76s]
[0m19:04:24.762499 [debug] [Thread-1  ]: Finished running node model.dbt_star.dbt_sandbox4__customers
[0m19:04:24.856901 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:892c34d4-13b6-4d5d-acc0-e876d78b87aa:northamerica-northeast1&page=queryresults
[0m19:04:24.858873 [debug] [Thread-2  ]: finished collecting timing info
[0m19:04:24.859518 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b97a96db-1766-466c-a58d-3d3ce13d99c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107838fa0>]}
[0m19:04:24.859881 [info ] [Thread-2  ]: 2 of 4 OK created sql table model dbt_sandbox16.dim_customers .................. [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 3.86s]
[0m19:04:24.860285 [debug] [Thread-2  ]: Finished running node model.dbt_star.dim_customers
[0m19:04:24.861725 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:04:24.862368 [info ] [MainThread]: 
[0m19:04:24.862652 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 5.28 seconds (5.28s).
[0m19:04:24.862894 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:04:24.863012 [debug] [MainThread]: Connection 'model.dbt_star.dbt_sandbox4__customers' was properly closed.
[0m19:04:24.863131 [debug] [MainThread]: Connection 'model.dbt_star.dim_customers' was properly closed.
[0m19:04:24.863239 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m19:04:24.863348 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m19:04:24.873104 [info ] [MainThread]: 
[0m19:04:24.873339 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:04:24.873542 [info ] [MainThread]: 
[0m19:04:24.873708 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m19:04:24.873942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076fdaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776c0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107881af0>]}
[0m19:04:24.874114 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 19:08:55.359418 | bc1c2249-37d4-4a0c-91c5-00c586cca77e ==============================
[0m19:08:55.359435 [info ] [MainThread]: Running with dbt=1.3.0
[0m19:08:55.359767 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:08:55.359848 [debug] [MainThread]: Tracking: tracking
[0m19:08:55.377646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220d47c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220d4940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220d48e0>]}
[0m19:08:55.423035 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:08:55.423172 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:08:55.423402 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.example.example
- models.dbt_sandbox3.dbt_sandbox3

[0m19:08:55.426763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12227a0d0>]}
[0m19:08:55.431052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122184a90>]}
[0m19:08:55.431198 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m19:08:55.431320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122184b20>]}
[0m19:08:55.432057 [info ] [MainThread]: 
[0m19:08:55.432366 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:08:55.432887 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m19:08:55.432985 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:08:56.545815 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m19:08:56.546386 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:08:56.763836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12223dc10>]}
[0m19:08:56.764770 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:08:56.765041 [info ] [MainThread]: 
[0m19:08:56.769471 [debug] [Thread-1  ]: Began running node model.dbt_star.dbt_sandbox4__customers
[0m19:08:56.769746 [debug] [Thread-2  ]: Began running node model.dbt_star.dim_customers
[0m19:08:56.769889 [debug] [Thread-3  ]: Began running node model.dbt_star.my_first_dbt_model
[0m19:08:56.770138 [info ] [Thread-1  ]: 1 of 4 START sql table model dbt_sandbox16.dbt_sandbox4__customers ............. [RUN]
[0m19:08:56.770489 [info ] [Thread-2  ]: 2 of 4 START sql table model dbt_sandbox16.dim_customers ....................... [RUN]
[0m19:08:56.770737 [info ] [Thread-3  ]: 3 of 4 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m19:08:56.771809 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.dbt_sandbox4__customers"
[0m19:08:56.772603 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.dbt_star.dim_customers"
[0m19:08:56.772795 [debug] [Thread-1  ]: Began compiling node model.dbt_star.dbt_sandbox4__customers
[0m19:08:56.773480 [debug] [Thread-3  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m19:08:56.773672 [debug] [Thread-2  ]: Began compiling node model.dbt_star.dim_customers
[0m19:08:56.773859 [debug] [Thread-1  ]: Compiling model.dbt_star.dbt_sandbox4__customers
[0m19:08:56.773982 [debug] [Thread-3  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m19:08:56.774089 [debug] [Thread-2  ]: Compiling model.dbt_star.dim_customers
[0m19:08:56.777690 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.dbt_sandbox4__customers"
[0m19:08:56.777848 [debug] [Thread-3  ]: Compiling model.dbt_star.my_first_dbt_model
[0m19:08:56.779980 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_star.dim_customers"
[0m19:08:56.783417 [debug] [Thread-1  ]: finished collecting timing info
[0m19:08:56.788481 [debug] [Thread-3  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m19:08:56.788627 [debug] [Thread-1  ]: Began executing node model.dbt_star.dbt_sandbox4__customers
[0m19:08:56.788709 [debug] [Thread-2  ]: finished collecting timing info
[0m19:08:56.801135 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:08:56.801297 [debug] [Thread-2  ]: Began executing node model.dbt_star.dim_customers
[0m19:08:56.803353 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:08:56.803465 [debug] [Thread-3  ]: finished collecting timing info
[0m19:08:56.803808 [debug] [Thread-3  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m19:08:56.805222 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m19:08:57.074761 [debug] [Thread-3  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m19:08:57.076000 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_star.dim_customers"
[0m19:08:57.076837 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.dbt_sandbox4__customers"
[0m19:08:57.077450 [debug] [Thread-1  ]: On model.dbt_star.dbt_sandbox4__customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dbt_sandbox4__customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dbt_sandbox4__customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:08:57.077587 [debug] [Thread-3  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m19:08:57.077697 [debug] [Thread-2  ]: On model.dbt_star.dim_customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dim_customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dim_customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:08:58.762547 [debug] [Thread-3  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:2a8887dc-28f5-4762-8614-e9ff265e69d9:northamerica-northeast1&page=queryresults
[0m19:08:58.785151 [debug] [Thread-3  ]: finished collecting timing info
[0m19:08:58.785874 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222edc40>]}
[0m19:08:58.786262 [info ] [Thread-3  ]: 3 of 4 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.01s]
[0m19:08:58.786661 [debug] [Thread-3  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m19:08:58.787061 [debug] [Thread-4  ]: Began running node model.dbt_star.my_second_dbt_model
[0m19:08:58.787250 [info ] [Thread-4  ]: 4 of 4 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m19:08:58.787749 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m19:08:58.787874 [debug] [Thread-4  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m19:08:58.787994 [debug] [Thread-4  ]: Compiling model.dbt_star.my_second_dbt_model
[0m19:08:58.790783 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m19:08:58.791655 [debug] [Thread-4  ]: finished collecting timing info
[0m19:08:58.791780 [debug] [Thread-4  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m19:08:58.808285 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m19:08:58.809141 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:08:58.809299 [debug] [Thread-4  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m19:08:59.504399 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:8b7f7eb6-6e27-46a8-8bcc-149168fcee52:northamerica-northeast1&page=queryresults
[0m19:08:59.506411 [debug] [Thread-4  ]: finished collecting timing info
[0m19:08:59.507072 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222ff2e0>]}
[0m19:08:59.507396 [info ] [Thread-4  ]: 4 of 4 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.72s]
[0m19:08:59.507749 [debug] [Thread-4  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m19:09:00.650857 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:113e8d7f-7285-45b6-b91a-c3d87f7fca8e:northamerica-northeast1&page=queryresults
[0m19:09:00.653495 [debug] [Thread-2  ]: finished collecting timing info
[0m19:09:00.654513 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122371220>]}
[0m19:09:00.655487 [info ] [Thread-2  ]: 2 of 4 OK created sql table model dbt_sandbox16.dim_customers .................. [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 3.88s]
[0m19:09:00.656201 [debug] [Thread-2  ]: Finished running node model.dbt_star.dim_customers
[0m19:09:00.743440 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:42b095f8-e1e6-4b0a-8dd3-c28cfb6994e7:northamerica-northeast1&page=queryresults
[0m19:09:00.745259 [debug] [Thread-1  ]: finished collecting timing info
[0m19:09:00.745810 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc1c2249-37d4-4a0c-91c5-00c586cca77e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222edaf0>]}
[0m19:09:00.746123 [info ] [Thread-1  ]: 1 of 4 OK created sql table model dbt_sandbox16.dbt_sandbox4__customers ........ [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 3.97s]
[0m19:09:00.746469 [debug] [Thread-1  ]: Finished running node model.dbt_star.dbt_sandbox4__customers
[0m19:09:00.747669 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:09:00.748157 [info ] [MainThread]: 
[0m19:09:00.748375 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 5.32 seconds (5.32s).
[0m19:09:00.748584 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:09:00.748684 [debug] [MainThread]: Connection 'model.dbt_star.dbt_sandbox4__customers' was properly closed.
[0m19:09:00.748779 [debug] [MainThread]: Connection 'model.dbt_star.dim_customers' was properly closed.
[0m19:09:00.748874 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m19:09:00.748971 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m19:09:00.758449 [info ] [MainThread]: 
[0m19:09:00.758718 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:09:00.758911 [info ] [MainThread]: 
[0m19:09:00.759057 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m19:09:00.759277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221845e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1221843d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222d6fa0>]}
[0m19:09:00.759449 [debug] [MainThread]: Flushing usage events


============================== 2022-11-23 19:14:07.969643 | a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d ==============================
[0m19:14:07.969672 [info ] [MainThread]: Running with dbt=1.3.0
[0m19:14:07.970020 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/jitesh.soni/Documents/Code/dbt_star', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m19:14:07.970099 [debug] [MainThread]: Tracking: tracking
[0m19:14:07.984162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114175e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111417760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111417700>]}
[0m19:14:08.029229 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 2 files added, 0 files changed.
[0m19:14:08.029464 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox3/dbt_sandbox3__customers.sql
[0m19:14:08.029572 [debug] [MainThread]: Partial parsing: added file: dbt_star://models/dbt_sandbox3/schema.yml
[0m19:14:08.029637 [debug] [MainThread]: Partial parsing: deleted file: dbt_star://models/dbt_sandbox4/dbt_sandbox4__customers.sql
[0m19:14:08.029690 [debug] [MainThread]: Partial parsing: deleted file: dbt_star://models/example/dim_customers.sql
[0m19:14:08.036828 [debug] [MainThread]: 1699: static parser successfully parsed dbt_sandbox3/dbt_sandbox3__customers.sql
[0m19:14:08.052304 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_sandbox3.dbt_sandbox3
- models.example.example

[0m19:14:08.055302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116112b0>]}
[0m19:14:08.060267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11152d9d0>]}
[0m19:14:08.060522 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m19:14:08.060667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11157b5e0>]}
[0m19:14:08.061562 [info ] [MainThread]: 
[0m19:14:08.061909 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:14:08.062439 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox"
[0m19:14:08.062554 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:09.262462 [debug] [ThreadPool]: Acquiring new bigquery connection "list_ae-recruitment-sandbox_dbt_sandbox16"
[0m19:14:09.262950 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:14:09.467922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107785370>]}
[0m19:14:09.470996 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:14:09.472284 [info ] [MainThread]: 
[0m19:14:09.478703 [debug] [Thread-1  ]: Began running node model.dbt_star.dbt_sandbox3__customers
[0m19:14:09.478971 [debug] [Thread-2  ]: Began running node model.dbt_star.my_first_dbt_model
[0m19:14:09.479273 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_sandbox16.dbt_sandbox3__customers ............. [RUN]
[0m19:14:09.479546 [info ] [Thread-2  ]: 2 of 3 START sql table model dbt_sandbox16.my_first_dbt_model .................. [RUN]
[0m19:14:09.480300 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.dbt_star.dbt_sandbox3__customers"
[0m19:14:09.480945 [debug] [Thread-2  ]: Acquiring new bigquery connection "model.dbt_star.my_first_dbt_model"
[0m19:14:09.481125 [debug] [Thread-1  ]: Began compiling node model.dbt_star.dbt_sandbox3__customers
[0m19:14:09.481267 [debug] [Thread-2  ]: Began compiling node model.dbt_star.my_first_dbt_model
[0m19:14:09.481457 [debug] [Thread-1  ]: Compiling model.dbt_star.dbt_sandbox3__customers
[0m19:14:09.481594 [debug] [Thread-2  ]: Compiling model.dbt_star.my_first_dbt_model
[0m19:14:09.485622 [debug] [Thread-1  ]: Writing injected SQL for node "model.dbt_star.dbt_sandbox3__customers"
[0m19:14:09.488125 [debug] [Thread-2  ]: Writing injected SQL for node "model.dbt_star.my_first_dbt_model"
[0m19:14:09.488752 [debug] [Thread-1  ]: finished collecting timing info
[0m19:14:09.488829 [debug] [Thread-2  ]: finished collecting timing info
[0m19:14:09.488918 [debug] [Thread-1  ]: Began executing node model.dbt_star.dbt_sandbox3__customers
[0m19:14:09.488993 [debug] [Thread-2  ]: Began executing node model.dbt_star.my_first_dbt_model
[0m19:14:09.503886 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m19:14:09.525002 [debug] [Thread-1  ]: Writing runtime sql for node "model.dbt_star.dbt_sandbox3__customers"
[0m19:14:09.525785 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:14:09.525960 [debug] [Thread-1  ]: On model.dbt_star.dbt_sandbox3__customers: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.dbt_sandbox3__customers"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`dbt_sandbox3__customers`
    
    
    OPTIONS()
    as (
      

with cust_orders AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , order_id
      , order_status
      , order_purchase_timestamp
      , order_approved_at
      , order_delivered_carrier_date
      , order_delivered_customer_date
      , order_estimated_delivery_date
FROM `ae-recruitment-sandbox.raw.customers` customers
LEFT JOIN `ae-recruitment-sandbox.raw.orders` orders
  ON customers.customer_id = orders.customer_id
)
,
final AS (
    SELECT customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
      , COUNT(DISTINCT order_id) AS num_orders
      , MIN(order_purchase_timestamp) AS earliest_order
      , MAX(order_purchase_timestamp) AS recent_order
FROM cust_orders
GROUP BY customer_unique_id
      , customer_city
      , customer_state
      , customer_zip_code_prefix
        )

SELECT * FROM final
    );
  
[0m19:14:09.726473 [debug] [Thread-2  ]: Writing runtime sql for node "model.dbt_star.my_first_dbt_model"
[0m19:14:09.727165 [debug] [Thread-2  ]: On model.dbt_star.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_first_dbt_model"} */

  
    

    create or replace table `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m19:14:11.337752 [debug] [Thread-2  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:4a7fc008-4629-40e6-9498-d0ea6f18a598:northamerica-northeast1&page=queryresults
[0m19:14:11.359006 [debug] [Thread-2  ]: finished collecting timing info
[0m19:14:11.359544 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c1bf40>]}
[0m19:14:11.359825 [info ] [Thread-2  ]: 2 of 3 OK created sql table model dbt_sandbox16.my_first_dbt_model ............. [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 1.88s]
[0m19:14:11.360147 [debug] [Thread-2  ]: Finished running node model.dbt_star.my_first_dbt_model
[0m19:14:11.360460 [debug] [Thread-4  ]: Began running node model.dbt_star.my_second_dbt_model
[0m19:14:11.360775 [info ] [Thread-4  ]: 3 of 3 START sql view model dbt_sandbox16.my_second_dbt_model .................. [RUN]
[0m19:14:11.361415 [debug] [Thread-4  ]: Acquiring new bigquery connection "model.dbt_star.my_second_dbt_model"
[0m19:14:11.361542 [debug] [Thread-4  ]: Began compiling node model.dbt_star.my_second_dbt_model
[0m19:14:11.361653 [debug] [Thread-4  ]: Compiling model.dbt_star.my_second_dbt_model
[0m19:14:11.364237 [debug] [Thread-4  ]: Writing injected SQL for node "model.dbt_star.my_second_dbt_model"
[0m19:14:11.364779 [debug] [Thread-4  ]: finished collecting timing info
[0m19:14:11.364961 [debug] [Thread-4  ]: Began executing node model.dbt_star.my_second_dbt_model
[0m19:14:11.381655 [debug] [Thread-4  ]: Writing runtime sql for node "model.dbt_star.my_second_dbt_model"
[0m19:14:11.382168 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m19:14:11.382296 [debug] [Thread-4  ]: On model.dbt_star.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "ae-recruitment-exercise16", "target_name": "dev", "node_id": "model.dbt_star.my_second_dbt_model"} */


  create or replace view `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `ae-recruitment-sandbox`.`dbt_sandbox16`.`my_first_dbt_model`
where id = 1;


[0m19:14:12.222771 [debug] [Thread-4  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:608f3be7-d9cf-4dea-8e7c-1a7bc1f032d8:northamerica-northeast1&page=queryresults
[0m19:14:12.225971 [debug] [Thread-4  ]: finished collecting timing info
[0m19:14:12.226896 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c52400>]}
[0m19:14:12.227357 [info ] [Thread-4  ]: 3 of 3 OK created sql view model dbt_sandbox16.my_second_dbt_model ............. [[32mCREATE VIEW (0 processed)[0m in 0.87s]
[0m19:14:12.227887 [debug] [Thread-4  ]: Finished running node model.dbt_star.my_second_dbt_model
[0m19:14:13.687506 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=ae-recruitment-sandbox&j=bq:9571a460-ce80-4bf8-b72a-e93966c7c7c6:northamerica-northeast1&page=queryresults
[0m19:14:13.690915 [debug] [Thread-1  ]: finished collecting timing info
[0m19:14:13.691918 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2efd8e2-7a0e-4d16-991d-7a208f2f2f4d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115ad8b0>]}
[0m19:14:13.692452 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_sandbox16.dbt_sandbox3__customers ........ [[32mCREATE TABLE (96.4k rows, 16.0 MB processed)[0m in 4.21s]
[0m19:14:13.692990 [debug] [Thread-1  ]: Finished running node model.dbt_star.dbt_sandbox3__customers
[0m19:14:13.694807 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m19:14:13.695454 [info ] [MainThread]: 
[0m19:14:13.695755 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 5.63 seconds (5.63s).
[0m19:14:13.696018 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:13.696144 [debug] [MainThread]: Connection 'model.dbt_star.dbt_sandbox3__customers' was properly closed.
[0m19:14:13.696263 [debug] [MainThread]: Connection 'model.dbt_star.my_first_dbt_model' was properly closed.
[0m19:14:13.696378 [debug] [MainThread]: Connection 'model.dbt_star.my_second_dbt_model' was properly closed.
[0m19:14:13.707543 [info ] [MainThread]: 
[0m19:14:13.707841 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:14:13.708092 [info ] [MainThread]: 
[0m19:14:13.708292 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m19:14:13.708586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11143f400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111592460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116033d0>]}
[0m19:14:13.708792 [debug] [MainThread]: Flushing usage events
